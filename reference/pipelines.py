import os
import time
import logging
import pandas as pd
import datetime
from openpyxl import load_workbook
from scrapy.exceptions import DropItem


class AmazonSpiderPipeline:
    def __init__(self):
        # --- [é…ç½®] ä¿å­˜ç›®å½• ---
        self.base_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "äº§å“é‡‡é›†æ•°æ®")
        if not os.path.exists(self.base_dir):
            os.makedirs(self.base_dir)

        # --- é…ç½®å‚æ•° ---
        self.batch_size = 100        # æ¯ 100 æ¡å†™å…¥ä¸€æ¬¡
        self.max_lines_per_file = 50000  # å•ä¸ª Excel æœ€å¤§è¡Œæ•°
        self.current_file_index = 1  # å½“å‰åˆ†å·åºå·
        self.current_file_lines = 0  # å½“å‰æ–‡ä»¶å·²å†™å…¥è¡Œæ•°

        # --- ç”Ÿæˆæœ¬æ¬¡è¿è¡Œçš„åŸºç¡€æ–‡ä»¶å ---
        self.timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        self._update_excel_path() # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ–‡ä»¶è·¯å¾„

        # --- ç”Ÿæˆæœ¬æ¬¡è¿è¡Œçš„æºç æ–‡ä»¶å¤¹ ---
        self.html_dir = os.path.join(self.base_dir, f"{self.timestamp}_source_html")
        if not os.path.exists(self.html_dir):
            os.makedirs(self.html_dir)

        self.data_buffer = []
        self.seen_asins = set()
        
        # --- å®æ—¶é€Ÿåº¦ç»Ÿè®¡ ---
        self.total_items_written = 0
        self.last_flush_time = time.time()
        self.start_time = time.time()
        
        self.logger = logging.getLogger('Pipeline')

        print(f"âœ… [åˆå§‹åŒ–] æ•°æ®æ–‡ä»¶: {self.excel_path}")

        # è¡¨å¤´æ˜ å°„
        self.header_map = {
            'crawl_time': 'å•†å“é‡‡é›†æ—¶é—´', 'zip_code': 'é…é€é‚®ç¼–', 'product_url': 'äº§å“é“¾æ¥',
            'asin': 'ASIN (å•†å“ID)', 'title': 'å•†å“æ ‡é¢˜',
            'original_price': 'å•†å“åŸä»·', 'current_price': 'å½“å‰ä»·æ ¼', 'buybox_price': 'BuyBox ä»·æ ¼',
            'buybox_shipping': 'BuyBox è¿è´¹', 'is_fba': 'æ˜¯å¦ FBA å‘è´§', 'stock_count': 'åº“å­˜æ•°é‡',
            'stock_status': 'åº“å­˜çŠ¶æ€', 'delivery_date': 'é…é€åˆ°è¾¾æ—¶é—´', 'delivery_time': 'é…é€æ—¶é•¿',
            'brand': 'å“ç‰Œ', 'model_number': 'äº§å“å‹å·', 'country_of_origin': 'åŸäº§å›½',
            'is_customized': 'æ˜¯å¦ä¸ºå®šåˆ¶äº§å“', 'best_sellers_rank': 'ç•…é”€æ’å', 'upc_list': 'UPC åˆ—è¡¨',
            'ean_list': 'EAN åˆ—è¡¨', 'package_dimensions': 'åŒ…è£…å°ºå¯¸', 'package_weight': 'åŒ…è£…é‡é‡',
            'item_dimensions': 'å•†å“æœ¬ä½“å°ºå¯¸', 'item_weight': 'å•†å“æœ¬ä½“é‡é‡', 'parent_asin': 'çˆ¶ä½“ ASIN',
            'variation_asins': 'å˜ä½“ ASIN åˆ—è¡¨', 'root_category_id': 'æ ¹ç±»ç›® ID', 'category_tree': 'ç±»ç›®è·¯å¾„æ ‘',
            'bullet_points': 'äº”ç‚¹æè¿°', 'image_urls': 'å•†å“å›¾ç‰‡é“¾æ¥', 'site': 'ç«™ç‚¹',
            'manufacturer': 'åˆ¶é€ å•†', 'part_number': 'éƒ¨ä»¶ç¼–å·', 'first_available_date': 'ä¸Šæ¶æ—¶é—´',
            'long_description': 'é•¿æè¿°', 'product_type': 'å•†å“ç±»å‹', 'category_ids': 'ç±»ç›® ID é“¾'
        }

        # åˆ—é¡ºåº
        self.column_order = [
            'å•†å“é‡‡é›†æ—¶é—´', 'é…é€é‚®ç¼–', 'äº§å“é“¾æ¥', 'ASIN (å•†å“ID)', 'å•†å“æ ‡é¢˜', 'å•†å“åŸä»·', 'å½“å‰ä»·æ ¼',
            'BuyBox ä»·æ ¼', 'BuyBox è¿è´¹', 'æ˜¯å¦ FBA å‘è´§', 'åº“å­˜æ•°é‡', 'åº“å­˜çŠ¶æ€',
            'é…é€åˆ°è¾¾æ—¶é—´', 'é…é€æ—¶é•¿', 'å“ç‰Œ', 'äº§å“å‹å·', 'åŸäº§å›½', 'æ˜¯å¦ä¸ºå®šåˆ¶äº§å“',
            'ç•…é”€æ’å', 'UPC åˆ—è¡¨', 'EAN åˆ—è¡¨', 'åŒ…è£…å°ºå¯¸', 'åŒ…è£…é‡é‡',
            'å•†å“æœ¬ä½“å°ºå¯¸', 'å•†å“æœ¬ä½“é‡é‡', 'çˆ¶ä½“ ASIN', 'å˜ä½“ ASIN åˆ—è¡¨', 'æ ¹ç±»ç›® ID',
            'ç±»ç›®è·¯å¾„æ ‘', 'äº”ç‚¹æè¿°', 'å•†å“å›¾ç‰‡é“¾æ¥', 'ç«™ç‚¹', 'åˆ¶é€ å•†', 'éƒ¨ä»¶ç¼–å·',
            'ä¸Šæ¶æ—¶é—´', 'é•¿æè¿°', 'å•†å“ç±»å‹', 'ç±»ç›® ID é“¾'
        ]

    def _update_excel_path(self):
        """æ›´æ–°å½“å‰ Excel æ–‡ä»¶è·¯å¾„"""
        self.excel_path = os.path.join(self.base_dir, f"{self.timestamp}_äº§å“é‡‡é›†_part{self.current_file_index}.xlsx")
        self.current_file_lines = 0

    def process_item(self, item, spider):
        asin = item.get('asin', 'UNKNOWN')
        title = item.get('title')

        # 1. æœ‰æ•ˆæ€§æ£€æŸ¥
        if not title or title == 'N/A':
            raise DropItem(f"âŒ [æ— æ•ˆæ•°æ®] ä¸¢å¼ƒ ASIN: {asin}")

        # 2. ASIN å»é‡
        if asin in self.seen_asins:
            raise DropItem(f"â™»ï¸ [é‡å¤æ•°æ®] ä¸¢å¼ƒ ASIN: {asin}")
        if asin: 
            self.seen_asins.add(asin)

        # 3. ä¿å­˜ HTML æºç  (æ ¹æ® settings å¼€å…³)
        # é»˜è®¤ä¸º Falseï¼Œåªæœ‰ Explicitly Set True æ‰ä¿å­˜
        save_html = spider.settings.getbool('SAVE_HTML_SOURCE', False)
        
        if save_html and 'source_html' in item:
            try:
                html_content = item.pop('source_html')
                if html_content:
                    safe_asin = "".join([c for c in asin if c.isalnum() or c in (' ', '.', '_')]).strip()
                    file_name = os.path.join(self.html_dir, f"{safe_asin}.html")
                    with open(file_name, 'w', encoding='utf-8') as f:
                        f.write(html_content)
            except Exception:
                pass
        else:
            # å¦‚æœä¸ä¿å­˜ï¼Œä¹Ÿå¾—æŠŠå­—æ®µåˆ äº†ï¼Œå…å¾—å†™å…¥ Excel æŠ¥é”™æˆ–å å†…å­˜
            item.pop('source_html', None)

        # 4. åŠ å…¥ç¼“å†²åŒº
        self.data_buffer.append(dict(item))

        # 5. è½ç›˜æ£€æµ‹
        if len(self.data_buffer) >= self.batch_size:
            self.flush(spider)

        return item

    def close_spider(self, spider):
        """çˆ¬è™«ç»“æŸæ—¶ï¼Œå†™å…¥å‰©ä½™æ•°æ®"""
        self.flush(spider, force=True)
        
        # è®¡ç®—æ€»è€—æ—¶å’Œå¹³å‡é€Ÿåº¦
        total_time = time.time() - self.start_time
        avg_speed = self.total_items_written / total_time * 60 if total_time > 0 else 0
        
        print(f"\nğŸ‰ [é‡‡é›†å…¨éƒ¨å®Œæˆ]")
        print(f"ğŸ“Š æ€»è®¡é‡‡é›†: {self.total_items_written} æ¡ | å¹³å‡é€Ÿåº¦: {avg_speed:.1f} æ¡/min")
        print(f"ğŸ“‚ Excelæ–‡ä»¶: {self.excel_path} (æœ€æ–°å·)")
        if spider.settings.getbool('SAVE_HTML_SOURCE', False):
            print(f"ğŸ“‚ æºç æ–‡ä»¶å¤¹: {self.html_dir}\n")

    def flush(self, spider=None, force=False):
        if not self.data_buffer:
            return

        # --- æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å· ---
        # å¦‚æœå½“å‰æ–‡ä»¶å·²æ»¡ï¼ˆä¸”ä¸æ˜¯ç¬¬ä¸€æ¬¡å†™ï¼‰ï¼Œåˆ™åˆ‡æ¢æ–‡ä»¶
        if self.current_file_lines >= self.max_lines_per_file:
            self.current_file_index += 1
            self._update_excel_path()
            print(f"ğŸ“‚ [è‡ªåŠ¨åˆ†å·] è¾¾åˆ° {self.max_lines_per_file} æ¡ï¼Œåˆ‡æ¢åˆ°æ–°æ–‡ä»¶: {self.excel_path}")

        current_time = time.time()
        items_count = len(self.data_buffer)

        df = pd.DataFrame(self.data_buffer)
        df_export = df.rename(columns=self.header_map)

        final_cols = [c for c in self.column_order if c in df_export.columns]
        final_cols += [c for c in df_export.columns if c not in final_cols]
        df_export = df_export[final_cols]

        try:
            self._append_to_excel(df_export, self.excel_path)
            
            # æ›´æ–°ç»Ÿè®¡
            self.total_items_written += items_count
            self.current_file_lines += items_count # æ›´æ–°å½“å‰æ–‡ä»¶è¡Œæ•°
            
            # è®¡ç®—é€Ÿåº¦
            time_diff = current_time - self.last_flush_time
            speed = items_count / time_diff * 60 if time_diff > 0 else 0
            
            # æ–°æ—¥å¿—æ ¼å¼
            self.logger.info(
                f"âœ… [å†™å…¥] æœ¬æ¬¡ {items_count} æ¡ | "
                f"å·{self.current_file_index} å·²å­˜ {self.current_file_lines} | "
                f"æ€»è®¡ {self.total_items_written} | "
                f"é€Ÿåº¦ {speed:.1f}/min"
            )
            
            self.last_flush_time = current_time
            
        except Exception as e:
            self.logger.error(f"âŒ [å†™å…¥é”™è¯¯] {e}")

        self.data_buffer.clear()

    def _append_to_excel(self, df_export: pd.DataFrame, file_path: str):
        # 1. é¦–æ¬¡å†™å…¥
        if not os.path.exists(file_path):
            df_export.to_excel(file_path, index=False)
            return

        # 2. è¿½åŠ å†™å…¥
        try:
            book = load_workbook(file_path)
            start_row = book.active.max_row if book.active else 0
            book.close()
        except Exception:
            start_row = 0

        with pd.ExcelWriter(file_path, engine="openpyxl", mode="a", if_sheet_exists="overlay") as writer:
            df_export.to_excel(writer, index=False, header=False, startrow=start_row)