"""
Amazon äº§å“é‡‡é›†ç³»ç»Ÿ v2 - Worker é‡‡é›†å¼•æ“
è¿æ¥ä¸­å¤®æœåŠ¡å™¨ API æ‹‰å–ä»»åŠ¡ã€æ¨é€ç»“æœ
æ¯ä¸ª worker ç»´æŠ¤ç‹¬ç«‹ session
ä¸¥æ ¼ 5æ¬¡/s é™é€Ÿï¼ˆ200ms Â± 50ms éšæœºæŠ–åŠ¨ï¼‰
è¢«å°æ£€æµ‹ â†’ æ¢ IP + æ¢ session é‡è¯•ï¼Œæœ€å¤š 3 æ¬¡
å¯åŠ¨æ–¹å¼ï¼špython worker.py --server http://x.x.x.x:8899
"""
import asyncio
import argparse
import logging
import random
import time
import uuid
import signal
import sys
from typing import Optional, Dict, List

from curl_cffi import requests as curl_requests

import config
from proxy import ProxyManager, get_proxy_manager
from session import AmazonSession
from parser import AmazonParser

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


class Worker:
    """å¼‚æ­¥é‡‡é›† Worker"""

    def __init__(self, server_url: str, worker_id: str = None, concurrency: int = None,
                 zip_code: str = None, fast_mode: bool = False):
        self.server_url = server_url.rstrip("/")
        self.worker_id = worker_id or f"worker-{uuid.uuid4().hex[:8]}"
        self.concurrency = concurrency or config.DEFAULT_CONCURRENCY
        self.zip_code = zip_code or config.DEFAULT_ZIP_CODE
        self.fast_mode = fast_mode  # å¿«é€Ÿæ¨¡å¼: AOD ä¼˜å…ˆè·å–ä»·æ ¼

        # ç»„ä»¶
        self.proxy_manager = get_proxy_manager()
        self.parser = AmazonParser()
        self._session: Optional[AmazonSession] = None

        # é€Ÿç‡æ§åˆ¶
        self._interval = config.REQUEST_INTERVAL
        self._jitter = config.REQUEST_JITTER
        self._semaphore = asyncio.Semaphore(self.concurrency)

        # ç»Ÿè®¡
        self._stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "blocked": 0,
            "start_time": None,
        }

        # è¿è¡Œæ§åˆ¶
        self._running = False

        # æ‰¹é‡æäº¤é˜Ÿåˆ—
        self._result_queue: asyncio.Queue = None  # åœ¨ start() ä¸­åˆå§‹åŒ–
        self._batch_submitter_task: Optional[asyncio.Task] = None
        self._batch_size = 10
        self._batch_interval = 2.0  # ç§’

        # Session è½®æ¢æ§åˆ¶
        self._success_since_rotate = 0
        self._rotate_every = config.SESSION_ROTATE_EVERY
        self._rotate_lock = asyncio.Lock()

    async def start(self):
        """å¯åŠ¨ Worker"""
        logger.info(f"ğŸš€ Worker [{self.worker_id}] å¯åŠ¨")
        logger.info(f"   æœåŠ¡å™¨: {self.server_url}")
        logger.info(f"   å¹¶å‘æ•°: {self.concurrency}")
        logger.info(f"   é‚®ç¼–: {self.zip_code}")
        logger.info(f"   å¿«é€Ÿæ¨¡å¼: {'å¼€å¯ (AODä¼˜å…ˆ)' if self.fast_mode else 'å…³é—­'}")

        self._running = True
        self._stats["start_time"] = time.time()

        # åˆå§‹åŒ–æ‰¹é‡æäº¤é˜Ÿåˆ—å’Œåå°ä»»åŠ¡
        self._result_queue = asyncio.Queue()
        self._batch_submitter_task = asyncio.create_task(self._batch_submitter())

        # åˆå§‹åŒ– session
        await self._init_session()

        # ä¸»å¾ªç¯ï¼šæŒç»­æ‹‰å–å’Œå¤„ç†ä»»åŠ¡
        while self._running:
            try:
                tasks = await self._pull_tasks()
                if not tasks:
                    logger.info("ğŸ“­ æš‚æ— ä»»åŠ¡ï¼Œç­‰å¾… 5 ç§’...")
                    await asyncio.sleep(5)
                    continue

                logger.info(f"ğŸ“‹ æ‹‰å–åˆ° {len(tasks)} ä¸ªä»»åŠ¡")

                # å¹¶å‘å¤„ç†ä»»åŠ¡
                sem_tasks = [self._process_with_semaphore(task) for task in tasks]
                await asyncio.gather(*sem_tasks, return_exceptions=True)

            except KeyboardInterrupt:
                break
            except Exception as e:
                logger.error(f"âŒ ä¸»å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(3)

        await self._cleanup()
        logger.info(f"ğŸ›‘ Worker [{self.worker_id}] å·²åœæ­¢")
        self._print_stats()

    async def stop(self):
        """åœæ­¢ Worker"""
        self._running = False

    async def _init_session(self):
        """åˆå§‹åŒ– Amazon session"""
        logger.info("ğŸ”§ åˆå§‹åŒ– Amazon session...")
        self._session = AmazonSession(self.proxy_manager, self.zip_code)
        success = await self._session.initialize()
        if not success:
            logger.warning("âš ï¸ Session åˆå§‹åŒ–å¤±è´¥ï¼Œå°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶é‡è¯•")
        self._success_since_rotate = 0

    async def _rotate_session(self, reason: str = "ä¸»åŠ¨è½®æ¢"):
        """è½®æ¢ sessionï¼šå…³é—­æ—§çš„ï¼Œåˆ·æ–°ä»£ç†ï¼Œåˆ›å»ºæ–°çš„"""
        async with self._rotate_lock:
            logger.info(f"ğŸ”„ Session {reason}...")
            if self._session:
                await self._session.close()
            await self.proxy_manager.report_blocked()
            await asyncio.sleep(1)
            self._session = AmazonSession(self.proxy_manager, self.zip_code)
            success = await self._session.initialize()
            self._success_since_rotate = 0
            if success:
                logger.info("ğŸ”„ Session è½®æ¢æˆåŠŸ")
            else:
                logger.warning("âš ï¸ Session è½®æ¢ååˆå§‹åŒ–å¤±è´¥")

    async def _pull_tasks(self) -> List[Dict]:
        """ä»æœåŠ¡å™¨æ‹‰å–ä»»åŠ¡"""
        try:
            url = f"{self.server_url}/api/tasks/pull"
            params = {
                "worker_id": self.worker_id,
                "count": self.concurrency,
            }
            resp = curl_requests.get(url, params=params, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                return data.get("tasks", [])
            else:
                logger.warning(f"æ‹‰å–ä»»åŠ¡å¤±è´¥: HTTP {resp.status_code}")
                return []
        except Exception as e:
            logger.error(f"æ‹‰å–ä»»åŠ¡å¼‚å¸¸: {e}")
            return []

    async def _process_with_semaphore(self, task: Dict):
        """å¸¦ä¿¡å·é‡çš„ä»»åŠ¡å¤„ç†ï¼ˆæ§åˆ¶å¹¶å‘ï¼‰"""
        async with self._semaphore:
            await self._process_task(task)

    async def _process_task(self, task: Dict):
        """
        å¤„ç†å•ä¸ªé‡‡é›†ä»»åŠ¡
        åŒºåˆ†è¶…æ—¶å’ŒçœŸæ­£çš„å°é”ï¼š
        - è¶…æ—¶/ç½‘ç»œé”™è¯¯ â†’ ç­‰å¾…åç›´æ¥é‡è¯•ï¼ˆä¸æ¢ IPï¼‰
        - éªŒè¯ç /403/503 â†’ æ¢ IP + æ¢ session â†’ é‡è¯•
        """
        asin = task["asin"]
        task_id = task["id"]
        zip_code = task.get("zip_code", self.zip_code)
        max_retries = config.MAX_RETRIES

        for attempt in range(max_retries):
            try:
                # é€Ÿç‡æ§åˆ¶ï¼š200ms Â± 50ms éšæœºæŠ–åŠ¨
                delay = self._interval + random.uniform(-self._jitter, self._jitter)
                await asyncio.sleep(delay)

                # å¿«é€Ÿæ¨¡å¼: å…ˆç”¨ AOD è·å–ä»·æ ¼æ•°æ®
                if self.fast_mode and attempt == 0:
                    aod_result = await self._try_aod_fast(asin, zip_code, task)
                    if aod_result is not None:
                        await self._submit_result(task_id, aod_result, success=True)
                        self._stats["success"] += 1
                        self._stats["total"] += 1
                        self._success_since_rotate += 1
                        title_short = aod_result["title"][:40] if aod_result.get("title") else "AOD"
                        logger.info(f"AOD {asin} | {title_short}... | {aod_result['buybox_price']}")
                        if self._success_since_rotate >= self._rotate_every:
                            await self._rotate_session(reason=f"ä¸»åŠ¨è½®æ¢ (å·²å®Œæˆ {self._success_since_rotate} æ¬¡)")
                        return

                # å‘èµ·è¯·æ±‚
                resp = await self._session.fetch_product_page(asin)

                # è¯·æ±‚å¤±è´¥ï¼ˆè¶…æ—¶/ç½‘ç»œå¼‚å¸¸ï¼‰â†’ ä¸æ¢ IPï¼Œç­‰å¾…åé‡è¯•
                if resp is None:
                    logger.warning(f"ASIN {asin} è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt+1}/{max_retries})")
                    await asyncio.sleep(2)
                    continue

                # çœŸæ­£è¢«å°ï¼ˆ403/503/éªŒè¯ç ï¼‰â†’ æ¢ IP + æ¢ session
                if self._session.is_blocked(resp):
                    self._stats["blocked"] += 1
                    logger.warning(f"ASIN {asin} è¢«å° HTTP {resp.status_code} (å°è¯• {attempt+1}/{max_retries})")
                    await self._rotate_session(reason="è¢«å°é”")
                    continue

                # 404 å¤„ç†
                if self._session.is_404(resp):
                    logger.info(f"ASIN {asin} å•†å“ä¸å­˜åœ¨ (404)")
                    result_data = self.parser._default_result(asin, zip_code)
                    result_data["title"] = "[å•†å“ä¸å­˜åœ¨]"
                    result_data["batch_name"] = task.get("batch_name", "")
                    await self._submit_result(task_id, result_data, success=True)
                    self._stats["success"] += 1
                    self._stats["total"] += 1
                    return

                # è§£æé¡µé¢
                result_data = self.parser.parse_product(resp.text, asin, zip_code)
                result_data["batch_name"] = task.get("batch_name", "")

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹¦æˆªé¡µé¢
                if result_data["title"] in ["[éªŒè¯ç æ‹¦æˆª]", "[APIå°é”]"]:
                    self._stats["blocked"] += 1
                    logger.warning(f"ASIN {asin} {result_data['title']} (å°è¯• {attempt+1}/{max_retries})")
                    await self._rotate_session(reason="é¡µé¢æ‹¦æˆª")
                    continue

                # æ ‡é¢˜ä¸ºç©ºè§†ä¸ºè½¯æ‹¦æˆª
                if not result_data["title"] or result_data["title"] == "N/A":
                    logger.warning(f"ASIN {asin} æ ‡é¢˜ä¸ºç©º (å°è¯• {attempt+1}/{max_retries})")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2)
                        continue

                # æˆåŠŸ
                await self._submit_result(task_id, result_data, success=True)
                self._stats["success"] += 1
                self._stats["total"] += 1
                self._success_since_rotate += 1

                title_short = result_data["title"][:40] if result_data["title"] else "N/A"
                logger.info(f"OK {asin} | {title_short}... | {result_data['current_price']}")

                # ä¸»åŠ¨è½®æ¢ï¼šæ¯ N æ¬¡æˆåŠŸè¯·æ±‚æ›´æ¢ session é˜²æ­¢è¢«æ£€æµ‹
                if self._success_since_rotate >= self._rotate_every:
                    await self._rotate_session(reason=f"ä¸»åŠ¨è½®æ¢ (å·²å®Œæˆ {self._success_since_rotate} æ¬¡)")

                return

            except Exception as e:
                logger.error(f"ASIN {asin} å¼‚å¸¸ (å°è¯• {attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2)
                    continue

        # æ‰€æœ‰é‡è¯•ç”¨å®Œï¼Œæ ‡è®°å¤±è´¥
        logger.error(f"ASIN {asin} é‡‡é›†å¤±è´¥ (å·²é‡è¯• {max_retries} æ¬¡)")
        await self._submit_result(task_id, None, success=False)
        self._stats["failed"] += 1
        self._stats["total"] += 1

    async def _try_aod_fast(self, asin: str, zip_code: str, task: Dict) -> Optional[Dict]:
        """
        AOD å¿«é€Ÿè·¯å¾„: ç”¨ AOD AJAX ç«¯ç‚¹è·å–ä»·æ ¼æ•°æ®
        æˆåŠŸè¿”å› result_dataï¼Œå¤±è´¥è¿”å› Noneï¼ˆä¼š fallback åˆ°äº§å“é¡µï¼‰
        """
        try:
            resp = await self._session.fetch_aod_page(asin)
            if resp is None:
                return None
            if self._session.is_blocked(resp):
                return None
            if resp.status_code != 200:
                return None

            aod_data = self.parser.parse_aod_response(resp.text, asin)

            # AOD å¿…é¡»è‡³å°‘æœ‰ä»·æ ¼æ‰ç®—æˆåŠŸ
            if not aod_data.get("offers") or aod_data["buybox_price"] == "N/A":
                return None

            # æ„å»ºå®Œæ•´ç»“æœï¼ˆAOD åªæœ‰ä»·æ ¼æ•°æ®ï¼Œå…¶ä»–å­—æ®µç•™é»˜è®¤ï¼‰
            result_data = self.parser._default_result(asin, zip_code)
            result_data["title"] = f"[AOD] {asin}"  # AOD ä¸åŒ…å«æ ‡é¢˜
            result_data["buybox_price"] = aod_data["buybox_price"]
            result_data["current_price"] = aod_data["buybox_price"]
            result_data["buybox_shipping"] = aod_data["buybox_shipping"]
            result_data["is_fba"] = aod_data["is_fba"]
            result_data["batch_name"] = task.get("batch_name", "")
            return result_data

        except Exception as e:
            logger.debug(f"AOD å¿«é€Ÿè·¯å¾„å¤±è´¥ {asin}: {e}")
            return None

    async def _submit_result(self, task_id: int, result_data: Optional[Dict], success: bool):
        """å°†ç»“æœæ”¾å…¥æ‰¹é‡æäº¤é˜Ÿåˆ—"""
        payload = {
            "task_id": task_id,
            "worker_id": self.worker_id,
            "success": success,
            "result": result_data,
        }
        await self._result_queue.put(payload)

    async def _batch_submitter(self):
        """åå°åç¨‹ï¼šæ¯æ”’å¤Ÿ batch_size ä¸ªæˆ–æ¯ batch_interval ç§’æ‰¹é‡æäº¤"""
        batch: List[Dict] = []
        while self._running or not self._result_queue.empty():
            try:
                # ç­‰å¾…é˜Ÿåˆ—ä¸­çš„æ•°æ®ï¼Œæœ€å¤šç­‰ batch_interval ç§’
                try:
                    item = await asyncio.wait_for(
                        self._result_queue.get(), timeout=self._batch_interval
                    )
                    batch.append(item)
                except asyncio.TimeoutError:
                    pass

                # å¿«é€Ÿæ’ç©ºé˜Ÿåˆ—ä¸­å·²æœ‰çš„æ•°æ®
                while not self._result_queue.empty() and len(batch) < self._batch_size:
                    batch.append(self._result_queue.get_nowait())

                # è¾¾åˆ°æ‰¹é‡å¤§å°æˆ–è¶…æ—¶ä¸”æœ‰æ•°æ® â†’ æäº¤
                if batch:
                    await self._submit_batch(batch)
                    batch = []

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ‰¹é‡æäº¤åç¨‹å¼‚å¸¸: {e}")
                await asyncio.sleep(1)

        # é€€å‡ºå‰åˆ·æ–°å‰©ä½™
        if batch:
            await self._submit_batch(batch)

    async def _flush_results(self):
        """åˆ·æ–°é˜Ÿåˆ—ä¸­æ‰€æœ‰å‰©ä½™ç»“æœ"""
        batch: List[Dict] = []
        while not self._result_queue.empty():
            batch.append(self._result_queue.get_nowait())
        if batch:
            await self._submit_batch(batch)

    async def _submit_batch(self, batch: List[Dict]):
        """æ‰¹é‡ POST æäº¤ç»“æœåˆ°æœåŠ¡å™¨"""
        try:
            url = f"{self.server_url}/api/tasks/result/batch"
            resp = curl_requests.post(
                url,
                json={"results": batch},
                timeout=15,
            )
            if resp.status_code == 200:
                logger.debug(f"æ‰¹é‡æäº¤ {len(batch)} æ¡ç»“æœæˆåŠŸ")
            else:
                logger.warning(f"æ‰¹é‡æäº¤å¤±è´¥ HTTP {resp.status_code}ï¼Œå›é€€é€æ¡æäº¤")
                await self._submit_batch_fallback(batch)
        except Exception as e:
            logger.error(f"æ‰¹é‡æäº¤å¼‚å¸¸: {e}ï¼Œå›é€€é€æ¡æäº¤")
            await self._submit_batch_fallback(batch)

    async def _submit_batch_fallback(self, batch: List[Dict]):
        """é€æ¡æäº¤ fallbackï¼ˆæ‰¹é‡æ¥å£ä¸å¯ç”¨æ—¶ï¼‰"""
        url = f"{self.server_url}/api/tasks/result"
        for payload in batch:
            try:
                resp = curl_requests.post(url, json=payload, timeout=10)
                if resp.status_code != 200:
                    logger.warning(f"é€æ¡æäº¤å¤±è´¥: task_id={payload.get('task_id')} HTTP {resp.status_code}")
            except Exception as e:
                logger.error(f"é€æ¡æäº¤å¼‚å¸¸: task_id={payload.get('task_id')} {e}")

    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        # åˆ·æ–°æ‰¹é‡æäº¤é˜Ÿåˆ—ä¸­çš„å‰©ä½™ç»“æœ
        if self._result_queue:
            await self._flush_results()
        if self._batch_submitter_task:
            self._batch_submitter_task.cancel()
            try:
                await self._batch_submitter_task
            except asyncio.CancelledError:
                pass
        if self._session:
            await self._session.close()

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        elapsed = time.time() - self._stats["start_time"] if self._stats["start_time"] else 0
        total = self._stats["total"]
        success = self._stats["success"]
        rate = success / total * 100 if total > 0 else 0
        speed = total / elapsed * 60 if elapsed > 0 else 0
        
        logger.info("=" * 50)
        logger.info(f"ğŸ“Š Worker [{self.worker_id}] ç»Ÿè®¡")
        logger.info(f"   æ€»é‡‡é›†: {total}")
        logger.info(f"   æˆåŠŸ: {success} ({rate:.1f}%)")
        logger.info(f"   å¤±è´¥: {self._stats['failed']}")
        logger.info(f"   è¢«å°: {self._stats['blocked']}")
        logger.info(f"   é€Ÿåº¦: {speed:.1f} æ¡/åˆ†é’Ÿ")
        logger.info(f"   è€—æ—¶: {elapsed:.0f} ç§’")
        logger.info("=" * 50)


def main():
    """Worker å…¥å£"""
    arg_parser = argparse.ArgumentParser(description="Amazon Scraper Worker")
    arg_parser.add_argument("--server", required=True, help="ä¸­å¤®æœåŠ¡å™¨åœ°å€ (å¦‚ http://192.168.1.100:8899)")
    arg_parser.add_argument("--worker-id", default=None, help="Worker IDï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰")
    arg_parser.add_argument("--concurrency", type=int, default=None, help=f"å¹¶å‘æ•°ï¼ˆé»˜è®¤ {config.DEFAULT_CONCURRENCY}ï¼‰")
    arg_parser.add_argument("--zip-code", default=None, help=f"é‚®ç¼–ï¼ˆé»˜è®¤ {config.DEFAULT_ZIP_CODE}ï¼‰")
    arg_parser.add_argument("--fast", action="store_true", help="å¿«é€Ÿæ¨¡å¼: AOD ä¼˜å…ˆè·å–ä»·æ ¼æ•°æ®")

    args = arg_parser.parse_args()

    worker = Worker(
        server_url=args.server,
        worker_id=args.worker_id,
        concurrency=args.concurrency,
        zip_code=args.zip_code,
        fast_mode=args.fast,
    )

    # ä¼˜é›…é€€å‡º
    loop = asyncio.new_event_loop()
    
    def signal_handler(sig, frame):
        logger.info("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        loop.create_task(worker.stop())
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        loop.run_until_complete(worker.start())
    finally:
        loop.close()


if __name__ == "__main__":
    main()
