"""
Amazon äº§å“é‡‡é›†ç³»ç»Ÿ v2 - Worker é‡‡é›†å¼•æ“ï¼ˆæµæ°´çº¿ + è‡ªé€‚åº”å¹¶å‘ï¼‰

æ¶æ„ï¼š
  task_feeder  â†’ [task_queue] â†’ worker_pool (Nä¸ªç‹¬ç«‹åç¨‹) â†’ [result_queue] â†’ batch_submitter
  
  adaptive_controller å®æ—¶è°ƒæ•´ N çš„å¤§å°

è¿æ¥ä¸­å¤®æœåŠ¡å™¨ API æ‹‰å–ä»»åŠ¡ã€æ¨é€ç»“æœ
å¯åŠ¨æ–¹å¼ï¼špython worker.py --server http://x.x.x.x:8899
"""
import asyncio
import argparse
import logging
import time
import uuid
import signal
import sys
from typing import Optional, Dict, List

import httpx

import config
from proxy import get_proxy_manager
from session import AmazonSession, SessionPool
from parser import AmazonParser
from metrics import MetricsCollector
from adaptive import AdaptiveController, TokenBucket

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


class Worker:
    """æµæ°´çº¿å¼‚æ­¥é‡‡é›† Worker"""

    def __init__(self, server_url: str, worker_id: str = None, concurrency: int = None,
                 zip_code: str = None, fast_mode: bool = False):
        self.server_url = server_url.rstrip("/")
        self.worker_id = worker_id or f"worker-{uuid.uuid4().hex[:8]}"
        self.zip_code = zip_code or config.DEFAULT_ZIP_CODE
        self.fast_mode = fast_mode  # å¿«é€Ÿæ¨¡å¼: AOD ä¼˜å…ˆè·å–ä»·æ ¼

        # ä»£ç†æ¨¡å¼
        self._proxy_mode = config.PROXY_MODE

        # ç»„ä»¶
        self.proxy_manager = get_proxy_manager()
        self.parser = AmazonParser()
        self._session: Optional[AmazonSession] = None       # TPS æ¨¡å¼
        self._session_pool: Optional[SessionPool] = None    # éš§é“æ¨¡å¼

        # é€Ÿç‡æ§åˆ¶
        self._rate_limiter = TokenBucket()

        # è‡ªé€‚åº”å¹¶å‘æ§åˆ¶
        self._metrics = MetricsCollector()
        max_c = concurrency or config.MAX_CONCURRENCY
        self._controller = AdaptiveController(
            initial=config.INITIAL_CONCURRENCY,
            min_c=config.MIN_CONCURRENCY,
            max_c=max_c,
            metrics=self._metrics,
        )

        # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæµæ°´çº¿æ ¸å¿ƒï¼‰
        self._task_queue: asyncio.Queue = None
        self._queue_size = getattr(config, "TASK_QUEUE_SIZE", 100)
        self._prefetch_threshold = getattr(config, "TASK_PREFETCH_THRESHOLD", 0.5)

        # ç»Ÿè®¡
        self._stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "blocked": 0,
            "start_time": None,
        }

        # è¿è¡Œæ§åˆ¶
        self._running = False

        # æ‰¹é‡æäº¤é˜Ÿåˆ—
        self._result_queue: asyncio.Queue = None
        self._batch_submitter_task: Optional[asyncio.Task] = None
        self._batch_size = 10
        self._batch_interval = 2.0  # ç§’

        # å®ä¾‹çº§è¿è¡Œå‚æ•°ï¼ˆä¸æ±¡æŸ“å…¨å±€ configï¼‰
        self._max_retries = config.MAX_RETRIES

        # Session è½®æ¢æ§åˆ¶
        self._success_since_rotate = 0
        self._rotate_every = config.SESSION_ROTATE_EVERY
        self._rotate_lock = asyncio.Lock()
        self._last_rotate_time = 0.0  # è½®æ¢é˜²æŠ–ï¼ˆmonotonicï¼‰
        self._session_ready = asyncio.Event()  # Session å°±ç»ªä¿¡å·

        # Worker åç¨‹ç®¡ç†
        self._worker_tasks: List[asyncio.Task] = []

        # æˆªå›¾é˜Ÿåˆ—ï¼ˆæœ‰ç•Œï¼Œé˜²æ­¢å†…å­˜æ— é™å¢é•¿ï¼‰
        self._screenshot_queue: asyncio.Queue = None
        self._screenshot_concurrency = 3   # å¹¶å‘æˆªå›¾åç¨‹æ•°
        self._browser = None               # æŒä¹…åŒ– Playwright æµè§ˆå™¨å®ä¾‹
        self._playwright = None            # Playwright ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self._browser_lock = asyncio.Lock()  # æµè§ˆå™¨åˆå§‹åŒ–/å…³é—­é”

        # è®¾ç½®åŒæ­¥
        self._settings_version = 0

        # å…¨å±€å¹¶å‘åè°ƒ
        self._global_block_epoch = 0   # å·²å¤„ç†çš„å…¨å±€å°é” epoch
        self._recovery_jitter = 0.5    # Server åˆ†é…çš„æ¢å¤æŠ–åŠ¨ç³»æ•°

    async def start(self):
        """å¯åŠ¨ Workerï¼ˆæµæ°´çº¿æ¶æ„ï¼‰"""
        logger.info(f"ğŸš€ Worker [{self.worker_id}] å¯åŠ¨ï¼ˆæµæ°´çº¿æ¨¡å¼ï¼‰")
        logger.info(f"   æœåŠ¡å™¨: {self.server_url}")
        logger.info(f"   åˆå§‹å¹¶å‘: {self._controller.current_concurrency}")
        logger.info(f"   å¹¶å‘èŒƒå›´: [{config.MIN_CONCURRENCY}, {self._controller._max}]")
        logger.info(f"   é‚®ç¼–: {self.zip_code}")
        logger.info(f"   å¿«é€Ÿæ¨¡å¼: {'å¼€å¯ (AODä¼˜å…ˆ)' if self.fast_mode else 'å…³é—­'}")
        logger.info(f"   ä»£ç†æ¨¡å¼: {self._proxy_mode.upper()}"
                     + (f" ({config.TUNNEL_CHANNELS} é€šé“)" if self._proxy_mode == "tunnel" else ""))

        self._running = True
        self._stats["start_time"] = time.time()

        # åˆå§‹åŒ–é˜Ÿåˆ—
        self._task_queue = asyncio.Queue(maxsize=self._queue_size)
        self._result_queue = asyncio.Queue()
        self._screenshot_queue = asyncio.Queue(maxsize=200)  # æœ‰ç•Œé˜Ÿåˆ—ï¼Œé˜²æ­¢å†…å­˜æ— é™å¢é•¿

        # å¯åŠ¨å‰å…ˆä» Server æ‹‰å–è®¾ç½®ï¼ˆä»£ç†åœ°å€ã€é‚®ç¼–ç­‰ï¼‰ï¼Œè¿œç¨‹ Worker æ— éœ€æœ¬åœ°é…ç½®
        await self._pull_initial_settings()

        # åˆå§‹åŒ– sessionï¼ˆæ­¤æ—¶ proxy_api_url å·²ä» Server åŒæ­¥ï¼‰
        await self._init_session()

        # å¯åŠ¨è‡ªé€‚åº”æ§åˆ¶å™¨
        await self._controller.start()

        # å¯åŠ¨æ ¸å¿ƒåç¨‹ï¼ˆå«æˆªå›¾åå° workerï¼‰
        try:
            coroutines = [
                self._task_feeder(),         # 1. æŒç»­ä» Server æ‹‰ä»»åŠ¡
                self._worker_pool(),         # 2. å·¥äººæ± ï¼šè‡ªé€‚åº”å¹¶å‘
                self._batch_submitter(),     # 3. æ‰¹é‡å›ä¼ ç»“æœ
                self._screenshot_workers(),   # 4. æˆªå›¾æ¸²æŸ“ï¼ˆå¤šåç¨‹å¹¶å‘ï¼‰
                self._settings_sync(),       # 5. å®šæœŸåŒæ­¥æœåŠ¡ç«¯è®¾ç½®
            ]
            # éš§é“æ¨¡å¼ï¼šæ·»åŠ  IP è½®æ¢ç›‘æ§åç¨‹
            if self._proxy_mode == "tunnel":
                coroutines.append(self._ip_rotation_watcher())
            await asyncio.gather(*coroutines)
        except asyncio.CancelledError:
            pass

        await self._cleanup()
        logger.info(f"ğŸ›‘ Worker [{self.worker_id}] å·²åœæ­¢")
        self._print_stats()

    async def stop(self):
        """åœæ­¢ Worker"""
        self._running = False
        # å‘ä»»åŠ¡é˜Ÿåˆ—æ”¾å…¥ None å“¨å…µï¼Œå”¤é†’æ‰€æœ‰ç­‰å¾…çš„ worker
        for _ in range(self._controller._max):
            try:
                self._task_queue.put_nowait(None)
            except (asyncio.QueueFull, AttributeError):
                break

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æµæ°´çº¿ä¸‰å¤§ç»„ä»¶
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _task_feeder(self):
        """
        ä»»åŠ¡è¡¥ç»™åç¨‹ï¼šæŒç»­ä» Server æ‹‰ä»»åŠ¡ï¼Œä¿æŒé˜Ÿåˆ—ä¸ç©º

        å½“é˜Ÿåˆ—ä½äºé˜ˆå€¼æ—¶ï¼Œä¸»åŠ¨æ‹‰å–æ–°ä»»åŠ¡å¡«å……ã€‚
        å¦‚æœæ‹‰åˆ°é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆpriority > 0ï¼‰ï¼Œç«‹å³æ¸…ç©ºå½“å‰é˜Ÿåˆ—ï¼Œ
        è®© Worker ç§’çº§åˆ‡æ¢åˆ°æ–°æ‰¹æ¬¡ï¼ˆæ—§ä»»åŠ¡é è¶…æ—¶å›æ”¶ï¼‰ã€‚
        """
        logger.info("ğŸ“¡ ä»»åŠ¡è¡¥ç»™åç¨‹å¯åŠ¨")
        empty_streak = 0  # è¿ç»­ç©ºå“åº”è®¡æ•°

        while self._running:
            try:
                queue_size = self._task_queue.qsize()
                threshold = int(self._queue_size * self._prefetch_threshold)

                if queue_size < threshold:
                    # æ‹‰å–é‡ = å½“å‰å¹¶å‘æ•°çš„ 2 å€ï¼ˆé¢„å–ï¼‰ï¼Œä½†ä¸è¶…è¿‡é˜Ÿåˆ—å‰©ä½™ç©ºé—´
                    fetch_count = min(
                        self._controller.current_concurrency * 2,
                        self._queue_size - queue_size,
                    )
                    fetch_count = max(fetch_count, 5)  # è‡³å°‘æ‹‰ 5 ä¸ª

                    tasks = await self._pull_tasks(count=fetch_count)

                    if tasks:
                        empty_streak = 0

                        # æ£€æµ‹æ˜¯å¦æœ‰é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆä¼˜å…ˆé‡‡é›†ï¼‰
                        has_priority = any(t.get("priority", 0) > 0 for t in tasks)
                        if has_priority and not self._task_queue.empty():
                            # æ”¶é›†è¢«æ¸…ç©ºçš„æ—§ä»»åŠ¡ IDï¼Œé€šçŸ¥ Server ç«‹å³å½’è¿˜
                            dropped_ids = []
                            while not self._task_queue.empty():
                                try:
                                    old_task = self._task_queue.get_nowait()
                                    if old_task and isinstance(old_task, dict):
                                        dropped_ids.append(old_task["id"])
                                except asyncio.QueueEmpty:
                                    break
                            logger.info(f"ğŸš€ æ£€æµ‹åˆ°ä¼˜å…ˆé‡‡é›†ä»»åŠ¡ï¼Œå·²æ¸…ç©ºé˜Ÿåˆ—ä¸­ {len(dropped_ids)} ä¸ªæ—§ä»»åŠ¡")
                            # å¼‚æ­¥é€šçŸ¥ Server å½’è¿˜æ—§ä»»åŠ¡ï¼ˆä¸é˜»å¡è¡¥ç»™æµç¨‹ï¼‰
                            if dropped_ids:
                                asyncio.create_task(self._release_tasks(dropped_ids))

                        for task in tasks:
                            await self._task_queue.put(task)
                        logger.debug(f"ğŸ“¡ è¡¥ç»™ {len(tasks)} ä¸ªä»»åŠ¡ (é˜Ÿåˆ—: {self._task_queue.qsize()})")
                    else:
                        empty_streak += 1
                        # æŒ‡æ•°é€€é¿ï¼šè¿ç»­ç©ºå“åº”æ—¶é€æ¸å¢åŠ ç­‰å¾…
                        wait = min(5 * (2 ** min(empty_streak - 1, 3)), 30)
                        logger.info(f"ğŸ“­ æš‚æ— ä»»åŠ¡ï¼Œç­‰å¾… {wait} ç§’... (é˜Ÿåˆ—å‰©ä½™: {queue_size})")
                        await asyncio.sleep(wait)
                else:
                    # é˜Ÿåˆ—å……è¶³ï¼ŒçŸ­æš‚ä¼‘æ¯
                    await asyncio.sleep(1)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ ä»»åŠ¡è¡¥ç»™å¼‚å¸¸: {e}")
                await asyncio.sleep(3)

        logger.info("ğŸ“¡ ä»»åŠ¡è¡¥ç»™åç¨‹é€€å‡º")

    async def _worker_pool(self):
        """
        å·¥äººæ± åç¨‹ï¼šç®¡ç†åŠ¨æ€æ•°é‡çš„ worker åç¨‹
        
        æ¯ä¸ª worker ç‹¬ç«‹å¾ªç¯ï¼šacquire â†’ å–ä»»åŠ¡ â†’ å¤„ç† â†’ release â†’ å¾ªç¯
        """
        logger.info("âš™ï¸ å·¥äººæ± å¯åŠ¨")
        
        # å¯åŠ¨åˆå§‹ worker åç¨‹ï¼Œé”™å¼€å¯åŠ¨æ—¶é—´
        initial = self._controller.current_concurrency
        for i in range(initial):
            task = asyncio.create_task(self._worker_loop(i))
            self._worker_tasks.append(task)

        # ç›‘æ§å¾ªç¯ï¼šæ ¹æ®å¹¶å‘å˜åŒ–åŠ¨æ€å¢å‡ worker
        last_target = initial
        while self._running:
            await asyncio.sleep(2)  # æ¯ 2 ç§’æ£€æŸ¥ä¸€æ¬¡
            
            target = self._controller.current_concurrency
            current = len([t for t in self._worker_tasks if not t.done()])
            
            if target > current:
                # éœ€è¦æ›´å¤š worker
                for i in range(target - current):
                    idx = len(self._worker_tasks)
                    task = asyncio.create_task(self._worker_loop(idx))
                    self._worker_tasks.append(task)
                if target != last_target:
                    logger.info(f"âš™ï¸ Worker æ‰©å®¹: {current} â†’ {target}")
            
            last_target = target
            
            # æ¸…ç†å·²å®Œæˆçš„ task å¼•ç”¨
            self._worker_tasks = [t for t in self._worker_tasks if not t.done()]

        # ç­‰å¾…æ‰€æœ‰ worker å®Œæˆ
        if self._worker_tasks:
            await asyncio.gather(*self._worker_tasks, return_exceptions=True)
        
        logger.info("âš™ï¸ å·¥äººæ± é€€å‡º")

    async def _worker_loop(self, worker_idx: int):
        """
        å•ä¸ª worker åç¨‹ï¼šæŒç»­å–ä»»åŠ¡å¤„ç†
        
        é”™å¼€å¯åŠ¨ â†’ acquire å¹¶å‘æ§½ â†’ å–ä»»åŠ¡ â†’ å¤„ç† â†’ release â†’ å¾ªç¯
        """
        # é”™å¼€å¯åŠ¨ï¼Œåˆ†æ•£è¯·æ±‚
        initial_c = self._controller.current_concurrency
        if initial_c > 0:
            stagger = worker_idx * (1.0 / initial_c)
            stagger = min(stagger, 2.0)  # æœ€å¤šé”™å¼€ 2 ç§’
            if stagger > 0:
                await asyncio.sleep(stagger)

        while self._running:
            try:
                # 1. è·å–å¹¶å‘æ§½ä½ï¼ˆè‡ªé€‚åº”æ§åˆ¶å™¨ç®¡æ§ï¼‰
                await self._controller.acquire()
                
                try:
                    # 2. ä»é˜Ÿåˆ—å–ä»»åŠ¡ï¼ˆæœ€å¤šç­‰ 5 ç§’ï¼‰
                    try:
                        task = await asyncio.wait_for(
                            self._task_queue.get(), timeout=5.0
                        )
                    except asyncio.TimeoutError:
                        # é˜Ÿåˆ—æš‚æ—¶ä¸ºç©ºï¼Œé‡Šæ”¾æ§½ä½åç»§ç»­ç­‰
                        continue
                    
                    # 3. å“¨å…µå€¼ â†’ é€€å‡º
                    if task is None:
                        break
                    
                    # 4. å¤„ç†ä»»åŠ¡ï¼ˆå¸¦è®¡æ—¶ï¼‰
                    start_time = time.time()
                    success, blocked, resp_bytes = await self._process_task(task)
                    elapsed = time.time() - start_time
                    
                    # 5. è®°å½•æŒ‡æ ‡
                    self._controller.record_result(
                        latency_s=elapsed,
                        success=success,
                        blocked=blocked,
                        resp_bytes=resp_bytes,
                    )
                finally:
                    # 6. é‡Šæ”¾å¹¶å‘æ§½ä½ï¼ˆä¿è¯ releaseï¼‰
                    self._controller.release()

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Worker-{worker_idx} å¼‚å¸¸: {e}")
                await asyncio.sleep(1)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ ¸å¿ƒå¤„ç†é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _pull_initial_settings(self):
        """å¯åŠ¨æ—¶ä» Server æ‹‰å–ä¸€æ¬¡è®¾ç½®ï¼Œç¡®ä¿æ‰€æœ‰è¿è¡Œå‚æ•°ä¸ Server ä¸€è‡´ã€‚
        è¿œç¨‹ Worker æ— éœ€æœ¬åœ° .env æˆ–ç¯å¢ƒå˜é‡ï¼Œæ‰€æœ‰é…ç½®ç”± Server ç»Ÿä¸€ä¸‹å‘ã€‚"""
        logger.info("âš™ï¸ ä»æœåŠ¡å™¨æ‹‰å–åˆå§‹è®¾ç½®...")
        try:
            async with httpx.AsyncClient(timeout=5) as client:
                resp = await client.get(f"{self.server_url}/api/settings")
                if resp.status_code != 200:
                    logger.warning(f"âš ï¸ æ‹‰å–åˆå§‹è®¾ç½®å¤±è´¥: HTTP {resp.status_code}")
                    return
                s = resp.json()

            changes = []

            # ä»£ç†æ¨¡å¼ï¼ˆæœ€å…³é”®ï¼šå†³å®š Worker çš„è¿è¡Œæ–¹å¼ï¼‰
            new_mode = s.get("proxy_mode")
            if new_mode and new_mode in ("tps", "tunnel") and new_mode != self._proxy_mode:
                self._proxy_mode = new_mode
                config.PROXY_MODE = new_mode  # noqa
                changes.append(f"proxy_mode={new_mode}")

            # éš§é“é…ç½®ï¼ˆè¿œç¨‹ Worker æœ¬åœ°å‡­è¯ä¸ºç©ºï¼Œå¿…é¡»ä» Server è·å–ï¼‰
            for cfg_key, cfg_attr in [
                ("tunnel_host", "TUNNEL_HOST"),
                ("tunnel_user", "TUNNEL_USER"),
                ("tunnel_pass", "TUNNEL_PASS"),
            ]:
                val = s.get(cfg_key)
                if val and val != getattr(config, cfg_attr, ""):
                    setattr(config, cfg_attr, val)
                    changes.append(cfg_key)
            tunnel_port = s.get("tunnel_port")
            if tunnel_port and tunnel_port != config.TUNNEL_PORT:
                config.TUNNEL_PORT = tunnel_port
                changes.append(f"tunnel_port={tunnel_port}")
            tunnel_channels = s.get("tunnel_channels")
            if tunnel_channels and tunnel_channels != config.TUNNEL_CHANNELS:
                config.TUNNEL_CHANNELS = tunnel_channels
                changes.append(f"tunnel_channels={tunnel_channels}")
            tunnel_rotate = s.get("tunnel_rotate_interval")
            if tunnel_rotate and tunnel_rotate != config.TUNNEL_ROTATE_INTERVAL:
                config.TUNNEL_ROTATE_INTERVAL = tunnel_rotate
                changes.append(f"tunnel_rotate={tunnel_rotate}")

            # ä»£ç† API åœ°å€ï¼ˆè¿œç¨‹ Worker æœ¬åœ°å‡­è¯ä¸ºç©ºï¼Œå¿…é¡»ä» Server è·å–ï¼‰
            new_proxy_url = s.get("proxy_api_url")
            if new_proxy_url and new_proxy_url != config.PROXY_API_URL_AUTH:
                config.PROXY_API_URL_AUTH = new_proxy_url  # noqa
                changes.append("proxy_api_url")

            # é‚®ç¼–ï¼ˆå‘½ä»¤è¡ŒæœªæŒ‡å®šæ—¶ï¼Œç”¨ Server ç«¯è®¾ç½®è¦†ç›–ï¼‰
            new_zip = s.get("zip_code")
            if new_zip and self.zip_code == config.DEFAULT_ZIP_CODE and new_zip != self.zip_code:
                self.zip_code = new_zip
                changes.append(f"zip_code={new_zip}")

            # ä»¤ç‰Œæ¡¶ QPS
            new_rate = s.get("token_bucket_rate")
            if new_rate and new_rate != self._rate_limiter.rate:
                self._rate_limiter.rate = new_rate
                changes.append(f"QPS={new_rate}")

            # å¹¶å‘æ§åˆ¶ï¼šmin / max / initialï¼ˆé¡ºåºï¼šå…ˆè®¾èŒƒå›´ï¼Œå†è®¾åˆå§‹å€¼ï¼‰
            new_min = s.get("min_concurrency")
            if new_min and new_min != self._controller._min:
                self._controller._min = new_min
                changes.append(f"min_c={new_min}")

            new_max = s.get("max_concurrency")
            if new_max and new_max != self._controller._max:
                self._controller._max = new_max
                changes.append(f"max_c={new_max}")

            new_initial = s.get("initial_concurrency")
            if new_initial and new_initial != self._controller._concurrency:
                # ç¡®ä¿åœ¨åˆæ³•èŒƒå›´å†…
                clamped = max(self._controller._min, min(self._controller._max, new_initial))
                self._controller._concurrency = clamped
                # å¯åŠ¨å‰é‡å»ºä¿¡å·é‡ï¼Œä½¿å…¶ä¸æ–°å¹¶å‘å€¼åŒ¹é…
                self._controller._semaphore = asyncio.Semaphore(clamped)
                changes.append(f"initial_c={clamped}")

            # æœ€å¤§é‡è¯•
            new_retries = s.get("max_retries")
            if new_retries and new_retries != self._max_retries:
                self._max_retries = new_retries
                changes.append(f"retries={new_retries}")

            # Session è½®æ¢
            new_rotate = s.get("session_rotate_every")
            if new_rotate and new_rotate != self._rotate_every:
                self._rotate_every = new_rotate
                changes.append(f"rotate={new_rotate}")

            # æˆªå›¾å¹¶å‘
            new_sc = s.get("screenshot_concurrency")
            if new_sc and new_sc != self._screenshot_concurrency:
                self._screenshot_concurrency = new_sc
                changes.append(f"screenshot_c={new_sc}")

            # AIMD è°ƒæ§å‚æ•°
            for attr, key in [
                ("_adjust_interval", "adjust_interval"),
                ("_target_latency", "target_latency"),
                ("_max_latency", "max_latency"),
                ("_target_success", "target_success_rate"),
                ("_min_success", "min_success_rate"),
                ("_block_threshold", "block_rate_threshold"),
                ("_cooldown_duration", "cooldown_after_block"),
            ]:
                val = s.get(key)
                if val is not None and val != getattr(self._controller, attr, None):
                    setattr(self._controller, attr, val)
                    changes.append(f"{key}={val}")

            self._settings_version = s.get("_version", 0)

            if changes:
                logger.info(f"âš™ï¸ åˆå§‹è®¾ç½®å·²åŒæ­¥: {', '.join(changes)}")
            else:
                logger.info("âš™ï¸ åˆå§‹è®¾ç½®å·²ç¡®è®¤ï¼ˆä¸æœ¬åœ°ä¸€è‡´ï¼‰")

        except Exception as e:
            logger.warning(f"âš ï¸ æ‹‰å–åˆå§‹è®¾ç½®å¼‚å¸¸ï¼ˆå°†ä½¿ç”¨æœ¬åœ°é…ç½®ï¼‰: {e}")

    async def _init_session(self):
        """åˆå§‹åŒ– Amazon sessionï¼ˆå¤±è´¥æ—¶é‡è¯•ï¼Œç¡®ä¿ _session_ready æœ€ç»ˆè¢« setï¼‰"""
        if self._proxy_mode == "tunnel":
            await self._init_session_tunnel()
        else:
            await self._init_session_tps()

    async def _init_session_tps(self):
        """TPS æ¨¡å¼ï¼šåˆå§‹åŒ–å•ä¸ªå…¨å±€ Session"""
        logger.info("ğŸ”§ åˆå§‹åŒ– Amazon session (TPS)...")
        self._session_ready.clear()
        for attempt in range(3):
            self._session = AmazonSession(self.proxy_manager, self.zip_code)
            success = await self._session.initialize()
            self._success_since_rotate = 0
            if success:
                self._session_ready.set()
                return
            # åˆå§‹åŒ–å¤±è´¥ï¼Œç­‰å¾…åé‡è¯•
            logger.warning(f"âš ï¸ Session åˆå§‹åŒ–å¤±è´¥ (å°è¯• {attempt+1}/3)")
            if self._session:
                await self._session.close()
            self._session = None
            if attempt < 2:
                await asyncio.sleep(5)
        # 3 æ¬¡å…¨éƒ¨å¤±è´¥ï¼Œä»ç„¶ set event è®© worker èµ°æ­£å¸¸çš„é‡è¯•/å¤±è´¥æµç¨‹
        logger.error("âŒ Session åˆå§‹åŒ– 3 æ¬¡å…¨éƒ¨å¤±è´¥ï¼ŒWorker å°†åœ¨å¤„ç†ä»»åŠ¡æ—¶ç»§ç»­é‡è¯•")
        self._session_ready.set()

    async def _init_session_tunnel(self):
        """éš§é“æ¨¡å¼ï¼šåˆå§‹åŒ– SessionPoolï¼Œé¢„çƒ­å‰å‡ ä¸ªé€šé“"""
        logger.info(f"ğŸ”§ åˆå§‹åŒ– SessionPool (éš§é“, {config.TUNNEL_CHANNELS} é€šé“)...")
        self._session_pool = SessionPool(self.proxy_manager, self.zip_code)
        # é¢„çƒ­å‰ 2 ä¸ªé€šé“ï¼ˆè‡³å°‘ 2 ä¸ªæ‰èƒ½è·‘æ»¡ 5Mbps æ€»å¸¦å®½ï¼‰
        warmup_count = min(2, config.TUNNEL_CHANNELS)
        warmup_ok = 0
        for ch_id in range(1, warmup_count + 1):
            session = await self._session_pool.get_session(ch_id)
            if session and session.is_ready():
                warmup_ok += 1
        if warmup_ok > 0:
            logger.info(f"âœ… SessionPool é¢„çƒ­å®Œæˆ: {warmup_ok}/{warmup_count} é€šé“å°±ç»ª")
        else:
            logger.error("âŒ SessionPool é¢„çƒ­å¤±è´¥: æ— å¯ç”¨é€šé“")
        # éš§é“æ¨¡å¼ä¸ä¾èµ– _session_readyï¼ˆæ¯æ¬¡è¯·æ±‚ç‹¬ç«‹è·å–é€šé“ sessionï¼‰
        self._session_ready.set()

    async def _rotate_session(self, reason: str = "ä¸»åŠ¨è½®æ¢"):
        """
        è½®æ¢ sessionï¼ˆä»… TPS æ¨¡å¼ï¼‰ã€‚
        éš§é“æ¨¡å¼ä¸‹ç”± proxy_manager.report_blocked(channel) + SessionPool å¤„ç†ã€‚
        """
        if self._proxy_mode == "tunnel":
            return  # éš§é“æ¨¡å¼ä¸ä½¿ç”¨å…¨å±€ session è½®æ¢
        async with self._rotate_lock:
            # é˜²æŠ–ï¼š5ç§’å†…ä¸é‡å¤è½®æ¢
            now = time.monotonic()
            if now - self._last_rotate_time < 5:
                logger.debug(f"ğŸ”„ è·³è¿‡è½®æ¢ï¼ˆè·ä¸Šæ¬¡ä¸è¶³5ç§’ï¼‰")
                return
            logger.info(f"ğŸ”„ Session {reason}...")
            # é€šçŸ¥æ‰€æœ‰ workerï¼šsession ä¸å¯ç”¨ï¼Œè¯·ç­‰å¾…
            self._session_ready.clear()
            if self._session:
                await self._session.close()
                self._session = None
            await self.proxy_manager.report_blocked()
            await asyncio.sleep(1)

            # è½®æ¢é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
            for attempt in range(3):
                self._session = AmazonSession(self.proxy_manager, self.zip_code)
                success = await self._session.initialize()
                self._success_since_rotate = 0
                self._last_rotate_time = time.monotonic()
                if success:
                    self._session_ready.set()
                    logger.info("ğŸ”„ Session è½®æ¢æˆåŠŸ")
                    return
                # å¤±è´¥ï¼Œæ¸…ç†åé‡è¯•
                logger.warning(f"âš ï¸ Session è½®æ¢åˆå§‹åŒ–å¤±è´¥ (å°è¯• {attempt+1}/3)")
                if self._session:
                    await self._session.close()
                self._session = None
                if attempt < 2:
                    await asyncio.sleep(3)

            # å…¨éƒ¨å¤±è´¥ï¼Œset event è®© worker èµ°æ­£å¸¸å¤±è´¥æµç¨‹
            logger.error("âŒ Session è½®æ¢ 3 æ¬¡å…¨éƒ¨å¤±è´¥")
            self._session_ready.set()

    async def _pull_tasks(self, count: int = None) -> List[Dict]:
        """ä»æœåŠ¡å™¨æ‹‰å–ä»»åŠ¡"""
        try:
            url = f"{self.server_url}/api/tasks/pull"
            params = {
                "worker_id": self.worker_id,
                "count": count or self._controller.current_concurrency,
            }
            async with httpx.AsyncClient(timeout=10) as client:
                resp = await client.get(url, params=params)
            if resp.status_code == 200:
                return resp.json().get("tasks", [])
            logger.warning(f"æ‹‰å–ä»»åŠ¡å¤±è´¥: HTTP {resp.status_code}")
            return []
        except Exception as e:
            logger.error(f"æ‹‰å–ä»»åŠ¡å¼‚å¸¸: {e}")
            return []

    async def _release_tasks(self, task_ids: List[int]):
        """é€šçŸ¥ Server å½’è¿˜æœªå¤„ç†çš„ä»»åŠ¡ï¼ˆä¼˜å…ˆé‡‡é›†åˆ‡æ¢æ—¶è°ƒç”¨ï¼‰"""
        try:
            url = f"{self.server_url}/api/tasks/release"
            async with httpx.AsyncClient(timeout=10) as client:
                resp = await client.post(url, json={"task_ids": task_ids})
            if resp.status_code == 200:
                data = resp.json()
                logger.info(f"å·²å½’è¿˜ {data.get('released', 0)} ä¸ªæ—§ä»»åŠ¡åˆ° pending")
            else:
                logger.warning(f"å½’è¿˜ä»»åŠ¡å¤±è´¥: HTTP {resp.status_code}")
        except Exception as e:
            logger.error(f"å½’è¿˜ä»»åŠ¡å¼‚å¸¸: {e}")

    async def _settings_sync(self):
        """å®šæœŸä¸ Server åŒæ­¥ï¼šä¸ŠæŠ¥ metrics + æ‹‰å– settings + æ¥æ”¶é…é¢"""
        logger.info("âš™ï¸ è®¾ç½®åŒæ­¥åç¨‹å¯åŠ¨ï¼ˆæ¯ 30 ç§’ï¼‰")
        while self._running:
            try:
                await asyncio.sleep(30)
                if not self._running:
                    break

                # æ”¶é›†æœ¬åœ° metrics å¿«ç…§
                snap = self._metrics.snapshot()
                payload = {
                    "worker_id": self.worker_id,
                    "metrics": {
                        "total": snap["total"],
                        "success_rate": snap["success_rate"],
                        "block_rate": snap["block_rate"],
                        "latency_p50": snap["latency_p50"],
                        "latency_p95": snap["latency_p95"],
                        "inflight": snap["inflight"],
                        "bandwidth_bps": snap["bandwidth_bps"],
                        "current_concurrency": self._controller.current_concurrency,
                    },
                }

                # ä¼˜å…ˆä½¿ç”¨æ–°çš„ç»¼åˆåŒæ­¥ç«¯ç‚¹
                s = None
                async with httpx.AsyncClient(timeout=5) as client:
                    try:
                        resp = await client.post(
                            f"{self.server_url}/api/worker/sync",
                            json=payload,
                        )
                        if resp.status_code == 200:
                            s = resp.json()
                    except Exception:
                        pass

                    # é™çº§ï¼šæ—§ç‰ˆ Server æ²¡æœ‰ /api/worker/sync
                    if s is None:
                        resp = await client.get(f"{self.server_url}/api/settings")
                        if resp.status_code == 200:
                            s = resp.json()

                if s is None:
                    continue

                # === ç°æœ‰ settings åŒæ­¥ ===
                ver = s.get("_version", 0)
                changes = []

                if ver > self._settings_version:
                    self._settings_version = ver

                    # ä»¤ç‰Œæ¡¶ QPSï¼ˆä»…åœ¨æ— é…é¢æ—¶ä½¿ç”¨å…¨å±€å€¼ï¼‰
                    if "_quota" not in s:
                        new_rate = s.get("token_bucket_rate")
                        if new_rate and new_rate != self._rate_limiter.rate:
                            self._rate_limiter.rate = new_rate
                            changes.append(f"QPS={new_rate}")

                    # å¹¶å‘èŒƒå›´ï¼ˆä»…åœ¨æ— é…é¢æ—¶ä½¿ç”¨å…¨å±€å€¼ï¼‰
                    if "_quota" not in s:
                        new_max = s.get("max_concurrency")
                        if new_max and new_max != self._controller._max:
                            self._controller._max = new_max
                            changes.append(f"max_c={new_max}")

                    new_min = s.get("min_concurrency")
                    if new_min and new_min != self._controller._min:
                        self._controller._min = new_min
                        changes.append(f"min_c={new_min}")

                    # AIMD è°ƒæ§å‚æ•°
                    for attr, key in [
                        ("_adjust_interval", "adjust_interval"),
                        ("_target_latency", "target_latency"),
                        ("_max_latency", "max_latency"),
                        ("_target_success", "target_success_rate"),
                        ("_min_success", "min_success_rate"),
                        ("_block_threshold", "block_rate_threshold"),
                        ("_cooldown_duration", "cooldown_after_block"),
                    ]:
                        val = s.get(key)
                        if val is not None and val != getattr(self._controller, attr, None):
                            setattr(self._controller, attr, val)
                            changes.append(f"{key}={val}")

                    # Session è½®æ¢
                    new_rotate = s.get("session_rotate_every")
                    if new_rotate and new_rotate != self._rotate_every:
                        self._rotate_every = new_rotate
                        changes.append(f"rotate={new_rotate}")

                    # æœ€å¤§é‡è¯•
                    new_retries = s.get("max_retries")
                    if new_retries and new_retries != self._max_retries:
                        self._max_retries = new_retries
                        changes.append(f"retries={new_retries}")

                    # æˆªå›¾å¹¶å‘æ•°
                    new_sc = s.get("screenshot_concurrency")
                    if new_sc and new_sc != self._screenshot_concurrency:
                        self._screenshot_concurrency = new_sc
                        changes.append(f"screenshot_c={new_sc}")

                    # ä»£ç† API åœ°å€
                    new_proxy_url = s.get("proxy_api_url")
                    if new_proxy_url and new_proxy_url != config.PROXY_API_URL_AUTH:
                        config.PROXY_API_URL_AUTH = new_proxy_url  # noqa
                        changes.append(f"proxy_url=***{new_proxy_url[-20:]}")

                    # ä»£ç†æ¨¡å¼ï¼ˆçƒ­åˆ‡æ¢ï¼šTPS â†” éš§é“ï¼‰
                    new_mode = s.get("proxy_mode")
                    if new_mode and new_mode in ("tps", "tunnel") and new_mode != self._proxy_mode:
                        self._proxy_mode = new_mode
                        config.PROXY_MODE = new_mode  # noqa
                        changes.append(f"proxy_mode={new_mode}")

                    # éš§é“é…ç½®
                    for cfg_key, cfg_attr in [
                        ("tunnel_host", "TUNNEL_HOST"),
                        ("tunnel_user", "TUNNEL_USER"),
                        ("tunnel_pass", "TUNNEL_PASS"),
                    ]:
                        val = s.get(cfg_key)
                        if val and val != getattr(config, cfg_attr, ""):
                            setattr(config, cfg_attr, val)
                            changes.append(cfg_key)
                    tunnel_port = s.get("tunnel_port")
                    if tunnel_port and tunnel_port != config.TUNNEL_PORT:
                        config.TUNNEL_PORT = tunnel_port
                        changes.append(f"tunnel_port={tunnel_port}")
                    tunnel_channels = s.get("tunnel_channels")
                    if tunnel_channels and tunnel_channels != config.TUNNEL_CHANNELS:
                        config.TUNNEL_CHANNELS = tunnel_channels
                        changes.append(f"tunnel_channels={tunnel_channels}")

                    if changes:
                        logger.info(f"âš™ï¸ è®¾ç½®å·²åŒæ­¥ (v{ver}): {', '.join(changes)}")

                # === é…é¢æ‰§è¡Œï¼ˆæ¯æ¬¡éƒ½æ‰§è¡Œï¼Œä¸å— version é™åˆ¶ï¼‰===
                quota = s.get("_quota")
                if quota:
                    new_max_c = quota.get("concurrency")
                    if new_max_c and new_max_c != self._controller._max:
                        old_max = self._controller._max
                        self._controller._max = new_max_c
                        # å½“å‰å¹¶å‘è¶…å‡ºé…é¢ â†’ å¼ºåˆ¶ç¼©å®¹
                        if self._controller._concurrency > new_max_c:
                            await self._controller._resize_semaphore(
                                self._controller._concurrency, new_max_c
                            )
                            self._controller._concurrency = new_max_c
                        logger.info(f"ğŸ“Š é…é¢: max_c {old_max}->{new_max_c}")

                    new_qps = quota.get("qps")
                    if new_qps and abs(new_qps - self._rate_limiter.rate) > 0.1:
                        old_qps = self._rate_limiter.rate
                        self._rate_limiter.rate = new_qps
                        logger.info(f"ğŸ“Š é…é¢: QPS {old_qps:.1f}->{new_qps:.1f}")

                # === å…¨å±€å°é”å¤„ç† ===
                block_info = s.get("_global_block", {})
                if block_info.get("active"):
                    epoch = block_info.get("epoch", 0)
                    if epoch > self._global_block_epoch:
                        self._global_block_epoch = epoch
                        # ç«‹å³å¹¶å‘å‡åŠ
                        new_c = max(
                            self._controller._min,
                            self._controller._concurrency // 2,
                        )
                        if new_c < self._controller._concurrency:
                            await self._controller._resize_semaphore(
                                self._controller._concurrency, new_c
                            )
                            self._controller._concurrency = new_c
                            # è®¾ç½®æœ¬åœ°å†·å´
                            remaining = block_info.get("remaining_s", 30)
                            self._controller._cooldown_until = time.monotonic() + remaining
                        logger.warning(
                            f"âš ï¸ å…¨å±€å°é” epoch={epoch}, "
                            f"å¹¶å‘ -> {new_c}, å†·å´ {block_info.get('remaining_s')}s"
                        )

                # === æ¢å¤æŠ–åŠ¨ç³»æ•° ===
                jitter = s.get("_recovery_jitter")
                if jitter is not None:
                    self._recovery_jitter = jitter
                    self._controller._recovery_jitter = jitter

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.debug(f"âš™ï¸ è®¾ç½®åŒæ­¥å¼‚å¸¸: {e}")

    async def _process_task(self, task: Dict) -> tuple:
        """
        å¤„ç†å•ä¸ªé‡‡é›†ä»»åŠ¡

        è¿”å›: (success: bool, blocked: bool, resp_bytes: int)

        åŒæ¨¡å¼åˆ†æ”¯ï¼š
        - TPS: æ‰€æœ‰ worker å…±äº«å…¨å±€ self._sessionï¼Œè¢«å°æ—¶è§¦å‘å…¨å±€ _rotate_session
        - éš§é“: æ¯æ¬¡è¯·æ±‚ä» proxy_manager åˆ†é…é€šé“ï¼Œä» session_pool å–å¯¹åº” sessionï¼Œ
                è¢«å°æ—¶ä»…æ ‡è®°è¯¥é€šé“ï¼Œä¸‹æ¬¡å¾ªç¯è‡ªåŠ¨åˆ‡åˆ°å…¶ä»–é€šé“
        """
        asin = task["asin"]
        task_id = task["id"]
        zip_code = task.get("zip_code", self.zip_code)
        max_retries = self._max_retries
        resp_bytes = 0
        last_error_type = "network"
        last_error_detail = ""
        is_tunnel = (self._proxy_mode == "tunnel")

        attempt = 0
        while attempt < max_retries:
            try:
                # å…¨å±€ä»¤ç‰Œæ¡¶é™æµï¼ˆæ›¿ä»£ per-worker sleepï¼Œç¡®ä¿ç³»ç»Ÿçº§ QPS ä¸è¶…æ ‡ï¼‰
                await self._rate_limiter.acquire()

                # === Session è·å–ï¼ˆæŒ‰æ¨¡å¼åˆ†æ”¯ï¼‰===
                session = None
                channel = None

                if is_tunnel:
                    # éš§é“æ¨¡å¼ï¼šä» proxy_manager åˆ†é…å¯ç”¨é€šé“
                    channel = self.proxy_manager.get_available_channel()
                    if channel is None:
                        # å…¨éƒ¨é€šé“è¢«å° â†’ ç­‰å¾… IP è½®æ¢
                        logger.warning(f"ASIN {asin} å…¨éƒ¨é€šé“è¢«å°ï¼Œç­‰å¾… IP è½®æ¢...")
                        await self.proxy_manager.wait_for_rotation()
                        attempt += 1
                        continue
                    session = await self._session_pool.get_session(channel)
                    if session is None or not session.is_ready():
                        attempt += 1
                        logger.warning(f"ASIN {asin} [ch{channel}] session æœªå°±ç»ª (å°è¯• {attempt}/{max_retries})")
                        await asyncio.sleep(2)
                        continue
                else:
                    # TPS æ¨¡å¼ï¼šç­‰å¾…å…¨å±€ session å°±ç»ª
                    if not self._session_ready.is_set():
                        logger.debug(f"ASIN {asin} ç­‰å¾… session å°±ç»ª...")
                        try:
                            await asyncio.wait_for(self._session_ready.wait(), timeout=30)
                        except asyncio.TimeoutError:
                            logger.warning(f"ASIN {asin} ç­‰å¾… session è¶…æ—¶ 30s")
                            attempt += 1
                            continue
                    if self._session is None or not self._session.is_ready():
                        attempt += 1
                        logger.warning(f"ASIN {asin} session ä»æœªå°±ç»ª (å°è¯• {attempt}/{max_retries})")
                        await asyncio.sleep(2)
                        continue
                    session = self._session

                ch_tag = f" [ch{channel}]" if is_tunnel else ""

                # å¿«é€Ÿæ¨¡å¼: å…ˆç”¨ AOD è·å–ä»·æ ¼æ•°æ®
                if self.fast_mode and attempt == 0:
                    aod_result = await self._try_aod_fast(asin, zip_code, task, session)
                    if aod_result is not None:
                        await self._submit_result(task_id, aod_result, success=True)
                        self._stats["success"] += 1
                        self._stats["total"] += 1
                        title_short = aod_result["title"][:40] if aod_result.get("title") else "AOD"
                        logger.info(f"AOD {asin}{ch_tag} | {title_short}... | {aod_result['buybox_price']}")
                        if not is_tunnel:
                            self._success_since_rotate += 1
                            if self._success_since_rotate >= self._rotate_every:
                                await self._rotate_session(reason=f"ä¸»åŠ¨è½®æ¢ (å·²å®Œæˆ {self._success_since_rotate} æ¬¡)")
                        return (True, False, resp_bytes)

                # å‘èµ·è¯·æ±‚
                resp = await session.fetch_product_page(asin)

                # è¯·æ±‚å¤±è´¥ï¼ˆè¶…æ—¶/ç½‘ç»œå¼‚å¸¸ï¼‰â†’ ä¸æ¢ IPï¼Œç­‰å¾…åé‡è¯•
                if resp is None:
                    attempt += 1
                    logger.warning(f"ASIN {asin}{ch_tag} è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt}/{max_retries})")
                    await asyncio.sleep(2)
                    continue

                # è®°å½•å“åº”å¤§å°
                resp_bytes = len(resp.content) if hasattr(resp, 'content') else 0

                # çœŸæ­£è¢«å°ï¼ˆ403/503/éªŒè¯ç ï¼‰
                if session.is_blocked(resp):
                    attempt += 1
                    self._stats["blocked"] += 1
                    last_error_type = "blocked"
                    last_error_detail = f"HTTP {resp.status_code}"
                    if is_tunnel:
                        logger.warning(f"ASIN {asin} [ch{channel}] è¢«å° HTTP {resp.status_code} (å°è¯• {attempt}/{max_retries})")
                        await self.proxy_manager.report_blocked(channel)
                        continue  # ç»§ç»­å¾ªç¯ â†’ ä¸‹æ¬¡åˆ†é…åˆ°å…¶ä»–é€šé“
                    else:
                        logger.warning(f"ASIN {asin} è¢«å° HTTP {resp.status_code} (å°è¯• {attempt}/{max_retries})")
                        await self._rotate_session(reason="è¢«å°é”")
                        return (False, True, resp_bytes)  # æ ‡è®°è¢«å°ï¼Œè®©æ§åˆ¶å™¨çŸ¥é“

                # 404 å¤„ç†
                if session.is_404(resp):
                    logger.info(f"ASIN {asin}{ch_tag} å•†å“ä¸å­˜åœ¨ (404)")
                    result_data = self.parser._default_result(asin, zip_code)
                    result_data["title"] = "[å•†å“ä¸å­˜åœ¨]"
                    result_data["batch_name"] = task.get("batch_name", "")
                    await self._submit_result(task_id, result_data, success=True)
                    self._stats["success"] += 1
                    self._stats["total"] += 1
                    return (True, False, resp_bytes)

                # è§£æé¡µé¢
                result_data = self.parser.parse_product(resp.text, asin, zip_code)
                result_data["batch_name"] = task.get("batch_name", "")

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹¦æˆªæˆ–ç©ºé¡µé¢
                title = result_data.get("title", "")
                if title == "[éªŒè¯ç æ‹¦æˆª]":
                    attempt += 1
                    self._stats["blocked"] += 1
                    last_error_type = "captcha"
                    last_error_detail = "validateCaptcha / Robot Check"
                    logger.warning(f"ASIN {asin}{ch_tag} {title} (å°è¯• {attempt}/{max_retries})")
                    if is_tunnel:
                        await self.proxy_manager.report_blocked(channel)
                    else:
                        await self._rotate_session(reason="é¡µé¢æ‹¦æˆª")
                    continue

                if title == "[APIå°é”]":
                    attempt += 1
                    self._stats["blocked"] += 1
                    last_error_type = "blocked"
                    last_error_detail = "api-services-support@amazon.com"
                    logger.warning(f"ASIN {asin}{ch_tag} {title} (å°è¯• {attempt}/{max_retries})")
                    if is_tunnel:
                        await self.proxy_manager.report_blocked(channel)
                    else:
                        await self._rotate_session(reason="é¡µé¢æ‹¦æˆª")
                    continue

                if title in ["[é¡µé¢ä¸ºç©º]", "[HTMLè§£æå¤±è´¥]"]:
                    attempt += 1
                    last_error_type = "parse_error"
                    last_error_detail = title
                    logger.warning(f"ASIN {asin}{ch_tag} {title} (å°è¯• {attempt}/{max_retries})")
                    await asyncio.sleep(2)
                    continue

                # æ ‡é¢˜ä¸ºç©ºè§†ä¸ºè½¯æ‹¦æˆªï¼Œé‡è¯•
                if not title or title == "N/A":
                    attempt += 1
                    last_error_type = "parse_error"
                    last_error_detail = "æ ‡é¢˜ä¸ºç©º"
                    logger.warning(f"ASIN {asin}{ch_tag} æ ‡é¢˜ä¸ºç©º (å°è¯• {attempt}/{max_retries})")
                    await asyncio.sleep(2)
                    continue

                # é‚®ç¼–/è´§å¸æ ¡éªŒï¼šæ£€æµ‹æ˜¯å¦é‡‡é›†åˆ°äº†éç¾å›½åœ°åŒºçš„æ•°æ®
                price = result_data.get("current_price", "")
                if price and price not in ["N/A", "ä¸å¯å”®", "See price in cart"]:
                    # ä»·æ ¼åº”åŒ…å« $ ç¬¦å·ï¼›å‡ºç° CNY/Â¥/â‚¬/Â£ è¯´æ˜é‚®ç¼–æ²¡ç”Ÿæ•ˆ
                    if any(c in price for c in ["Â¥", "â‚¬", "Â£", "CNY"]) or "$" not in price:
                        attempt += 1
                        last_error_type = "parse_error"
                        last_error_detail = f"éç¾å›½ä»·æ ¼: {price}"
                        logger.warning(f"ASIN {asin}{ch_tag} éç¾å›½ä»·æ ¼ '{price}' (å°è¯• {attempt}/{max_retries})")
                        if is_tunnel:
                            await self.proxy_manager.report_blocked(channel)
                        else:
                            await self._rotate_session(reason="éç¾å›½åŒºåŸŸæ•°æ®")
                        continue

                # æˆåŠŸ
                await self._submit_result(task_id, result_data, success=True)
                self._stats["success"] += 1
                self._stats["total"] += 1

                title_short = result_data["title"][:40] if result_data["title"] else "N/A"
                logger.info(f"OK {asin}{ch_tag} | {title_short}... | {result_data['current_price']}")

                # æˆªå›¾å­˜è¯ï¼šæ”¾å…¥æˆªå›¾é˜Ÿåˆ—ï¼ˆæ— é™é˜Ÿåˆ—ï¼Œä¸ä¼šä¸¢å¤±ï¼‰
                if task.get("needs_screenshot"):
                    await self._screenshot_queue.put({
                        "task_id": task_id,
                        "asin": asin,
                        "batch_name": task.get("batch_name", ""),
                        "html": resp.text,
                    })

                # ä¸»åŠ¨è½®æ¢ï¼šæ¯ N æ¬¡æˆåŠŸè¯·æ±‚æ›´æ¢ session é˜²æ­¢è¢«æ£€æµ‹ï¼ˆä»… TPS æ¨¡å¼ï¼‰
                if not is_tunnel:
                    self._success_since_rotate += 1
                    if self._success_since_rotate >= self._rotate_every:
                        await self._rotate_session(reason=f"ä¸»åŠ¨è½®æ¢ (å·²å®Œæˆ {self._success_since_rotate} æ¬¡)")

                return (True, False, resp_bytes)

            except Exception as e:
                attempt += 1
                err_name = type(e).__name__
                if "timeout" in err_name.lower() or "Timeout" in str(e):
                    last_error_type = "timeout"
                elif "connect" in err_name.lower() or "ConnectionError" in err_name:
                    last_error_type = "network"
                else:
                    last_error_type = "network"
                last_error_detail = f"{err_name}: {str(e)[:200]}"
                logger.error(f"ASIN {asin} å¼‚å¸¸ (å°è¯• {attempt}/{max_retries}): {e}")
                await asyncio.sleep(2)

        # æ‰€æœ‰é‡è¯•ç”¨å®Œï¼Œæ ‡è®°å¤±è´¥
        logger.error(f"ASIN {asin} é‡‡é›†å¤±è´¥ (å·²é‡è¯• {max_retries} æ¬¡) [{last_error_type}]")
        await self._submit_result(task_id, None, success=False,
                                  error_type=last_error_type, error_detail=last_error_detail)
        self._stats["failed"] += 1
        self._stats["total"] += 1
        return (False, False, resp_bytes)

    async def _try_aod_fast(self, asin: str, zip_code: str, task: Dict,
                            session: AmazonSession = None) -> Optional[Dict]:
        """
        AOD å¿«é€Ÿè·¯å¾„: ç”¨ AOD AJAX ç«¯ç‚¹è·å–ä»·æ ¼æ•°æ®
        æˆåŠŸè¿”å› result_dataï¼Œå¤±è´¥è¿”å› Noneï¼ˆä¼š fallback åˆ°äº§å“é¡µï¼‰

        Args:
            session: æŒ‡å®šä½¿ç”¨çš„ sessionï¼ˆéš§é“æ¨¡å¼ä¸‹ä¼ å…¥é€šé“ sessionï¼‰
        """
        session = session or self._session
        try:
            resp = await session.fetch_aod_page(asin)
            if resp is None:
                return None
            if session.is_blocked(resp):
                return None
            if resp.status_code != 200:
                return None

            aod_data = self.parser.parse_aod_response(resp.text, asin)

            # AOD å¿…é¡»è‡³å°‘æœ‰ä»·æ ¼æ‰ç®—æˆåŠŸ
            if not aod_data.get("offers") or aod_data["buybox_price"] == "N/A":
                return None

            # æ„å»ºå®Œæ•´ç»“æœï¼ˆAOD åªæœ‰ä»·æ ¼æ•°æ®ï¼Œå…¶ä»–å­—æ®µç•™é»˜è®¤ï¼‰
            result_data = self.parser._default_result(asin, zip_code)
            result_data["title"] = f"[AOD] {asin}"  # AOD ä¸åŒ…å«æ ‡é¢˜
            result_data["buybox_price"] = aod_data["buybox_price"]
            result_data["current_price"] = aod_data["buybox_price"]
            result_data["buybox_shipping"] = aod_data["buybox_shipping"]
            result_data["is_fba"] = aod_data["is_fba"]
            result_data["batch_name"] = task.get("batch_name", "")
            return result_data

        except Exception as e:
            logger.debug(f"AOD å¿«é€Ÿè·¯å¾„å¤±è´¥ {asin}: {e}")
            return None

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ç»“æœæäº¤ï¼ˆä¿æŒä¸å˜ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _submit_result(self, task_id: int, result_data: Optional[Dict], success: bool,
                             error_type: str = None, error_detail: str = None):
        """å°†ç»“æœæ”¾å…¥æ‰¹é‡æäº¤é˜Ÿåˆ—"""
        payload = {
            "task_id": task_id,
            "worker_id": self.worker_id,
            "success": success,
            "result": result_data,
        }
        if error_type:
            payload["error_type"] = error_type
            payload["error_detail"] = (error_detail or "")[:500]
        await self._result_queue.put(payload)

    async def _batch_submitter(self):
        """åå°åç¨‹ï¼šæ¯æ”’å¤Ÿ batch_size ä¸ªæˆ–æ¯ batch_interval ç§’æ‰¹é‡æäº¤"""
        batch: List[Dict] = []
        while self._running or not self._result_queue.empty():
            try:
                # ç­‰å¾…ç¬¬ä¸€æ¡æ•°æ®åˆ°æ¥ï¼ˆæœ€å¤šç­‰ batch_interval ç§’ï¼‰
                try:
                    item = await asyncio.wait_for(
                        self._result_queue.get(), timeout=self._batch_interval
                    )
                    batch.append(item)
                except asyncio.TimeoutError:
                    # è¶…æ—¶ä¸”æ— æ•°æ® â†’ ç»§ç»­ç­‰
                    if batch:
                        await self._submit_batch(batch)
                        batch = []
                    continue

                # æ‹¿åˆ°ç¬¬ä¸€æ¡åï¼Œåœ¨å‰©ä½™çª—å£å†…ç»§ç»­æ”’æ•°æ®
                deadline = asyncio.get_event_loop().time() + self._batch_interval
                while len(batch) < self._batch_size:
                    remaining = deadline - asyncio.get_event_loop().time()
                    if remaining <= 0:
                        break
                    try:
                        item = await asyncio.wait_for(
                            self._result_queue.get(), timeout=remaining
                        )
                        batch.append(item)
                    except asyncio.TimeoutError:
                        break  # çª—å£åˆ°æœŸ

                # æäº¤æ”’åˆ°çš„æ‰¹æ¬¡
                if batch:
                    await self._submit_batch(batch)
                    batch = []

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ‰¹é‡æäº¤åç¨‹å¼‚å¸¸: {e}")
                await asyncio.sleep(1)

        # é€€å‡ºå‰åˆ·æ–°å‰©ä½™
        if batch:
            await self._submit_batch(batch)

    async def _flush_results(self):
        """åˆ·æ–°é˜Ÿåˆ—ä¸­æ‰€æœ‰å‰©ä½™ç»“æœ"""
        batch: List[Dict] = []
        while not self._result_queue.empty():
            batch.append(self._result_queue.get_nowait())
        if batch:
            await self._submit_batch(batch)

    async def _submit_batch(self, batch: List[Dict], retry: int = 3):
        """æ‰¹é‡ POST æäº¤ç»“æœåˆ°æœåŠ¡å™¨ï¼ˆå«é‡è¯•ï¼‰"""
        url = f"{self.server_url}/api/tasks/result/batch"
        for attempt in range(retry):
            try:
                async with httpx.AsyncClient(timeout=15) as client:
                    resp = await client.post(url, json={"results": batch})
                if resp.status_code == 200:
                    logger.debug(f"æ‰¹é‡æäº¤ {len(batch)} æ¡ç»“æœæˆåŠŸ")
                    return
                logger.warning(f"æ‰¹é‡æäº¤å¤±è´¥ HTTP {resp.status_code} (å°è¯• {attempt+1}/{retry})")
            except Exception as e:
                logger.error(f"æ‰¹é‡æäº¤å¼‚å¸¸ (å°è¯• {attempt+1}/{retry}): {e}")
            if attempt < retry - 1:
                await asyncio.sleep(2 ** attempt)
        # å…¨éƒ¨é‡è¯•å¤±è´¥ï¼Œå›é€€é€æ¡æäº¤
        logger.error("æ‰¹é‡æäº¤å¤šæ¬¡å¤±è´¥ï¼Œå›é€€é€æ¡æäº¤")
        await self._submit_batch_fallback(batch)

    async def _submit_batch_fallback(self, batch: List[Dict]):
        """é€æ¡æäº¤ fallbackï¼ˆæ‰¹é‡æ¥å£ä¸å¯ç”¨æ—¶ï¼‰"""
        url = f"{self.server_url}/api/tasks/result"
        async with httpx.AsyncClient(timeout=10) as client:
            for payload in batch:
                try:
                    resp = await client.post(url, json=payload)
                    if resp.status_code != 200:
                        logger.warning(f"é€æ¡æäº¤å¤±è´¥: task_id={payload.get('task_id')} HTTP {resp.status_code}")
                except Exception as e:
                    logger.error(f"é€æ¡æäº¤å¼‚å¸¸: task_id={payload.get('task_id')} {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æˆªå›¾æ¸²æŸ“ç®¡é“
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _screenshot_workers(self):
        """
        æˆªå›¾åç¨‹æ± ï¼šåŠ¨æ€ç®¡ç†å¤šä¸ªå¹¶å‘æˆªå›¾åç¨‹ï¼Œå…±äº«åŒä¸€ä¸ª Playwright æµè§ˆå™¨å®ä¾‹ã€‚
        Playwright åŸç”Ÿæ”¯æŒå¤š page å¹¶å‘ï¼ˆæ¯ä¸ª page ç‹¬ç«‹æ¸²æŸ“ç®¡çº¿ï¼‰ï¼Œæ— çº¿ç¨‹å®‰å…¨é—®é¢˜ã€‚
        """
        n = self._screenshot_concurrency
        logger.info(f"ğŸ“¸ æˆªå›¾åç¨‹æ± å¯åŠ¨ï¼ˆ{n} å¹¶å‘ï¼‰")
        tasks: List[asyncio.Task] = []
        for i in range(n):
            tasks.append(asyncio.create_task(self._screenshot_loop(i)))

        # ç›‘æ§å¾ªç¯ï¼šåŠ¨æ€å¢å‡æˆªå›¾åç¨‹
        while self._running or not self._screenshot_queue.empty():
            await asyncio.sleep(3)
            target = self._screenshot_concurrency
            active = [t for t in tasks if not t.done()]
            current = len(active)
            if target > current:
                for i in range(target - current):
                    idx = len(tasks)
                    tasks.append(asyncio.create_task(self._screenshot_loop(idx)))
                logger.info(f"ğŸ“¸ æˆªå›¾åç¨‹æ‰©å®¹: {current} â†’ {target}")
            tasks = [t for t in tasks if not t.done()]

        # ç­‰å¾…æ‰€æœ‰æˆªå›¾åç¨‹å®Œæˆ
        remaining = [t for t in tasks if not t.done()]
        if remaining:
            await asyncio.gather(*remaining, return_exceptions=True)
        logger.info("ğŸ“¸ æˆªå›¾åç¨‹æ± é€€å‡º")

    async def _screenshot_loop(self, idx: int):
        """å•ä¸ªæˆªå›¾åç¨‹ï¼šä»é˜Ÿåˆ—å–ä»»åŠ¡ï¼Œæ¸²æŸ“å¹¶ä¸Šä¼ """
        while self._running or not self._screenshot_queue.empty():
            try:
                try:
                    item = await asyncio.wait_for(
                        self._screenshot_queue.get(), timeout=5.0
                    )
                except asyncio.TimeoutError:
                    continue

                asin = item["asin"]
                batch_name = item["batch_name"]
                html_content = item["html"]

                try:
                    png_bytes = await self._render_screenshot(html_content, asin)
                    if png_bytes:
                        await self._upload_screenshot(batch_name, asin, png_bytes)
                        logger.info(f"ğŸ“¸ æˆªå›¾å®Œæˆ: {asin} ({len(png_bytes)} bytes) [worker-{idx}]")
                    else:
                        logger.warning(f"ğŸ“¸ æˆªå›¾æ¸²æŸ“å¤±è´¥: {asin}")
                except Exception as e:
                    logger.error(f"ğŸ“¸ æˆªå›¾å¼‚å¸¸ {asin}: {e}")

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ğŸ“¸ æˆªå›¾åç¨‹ #{idx} å¼‚å¸¸: {e}")
                await asyncio.sleep(1)

    async def _render_screenshot(self, html_content: str, asin: str) -> Optional[bytes]:
        """
        ç”¨ Playwright æ¸²æŸ“ Amazon ç½‘é¡µæˆªå›¾

        ä¼˜åŒ–ç‚¹ï¼š
        1. setContent() ç›´æ¥æ³¨å…¥ HTMLï¼Œçœå» URL å¯¼èˆªå’Œä¸»æ–‡æ¡£æ‹¦æˆªå¼€é”€
        2. å±è”½ JS/å­—ä½“/åª’ä½“/è¿½è¸ªï¼Œåªä¿ç•™ CSS å’Œå›¾ç‰‡ä¿è¯é¡µé¢å¤–è§‚
        3. æ›´å¯é çš„è£å‰ªé€»è¾‘ï¼šæ‰«æå¤šä¸ªé”šç‚¹å…ƒç´ å–æœ€å¤§ bottom
        4. æµè§ˆå™¨æŒä¹…åŒ–å¤ç”¨ï¼Œpage çº§é”™è¯¯ä¸æ€æµè§ˆå™¨ï¼ˆé˜²æ­¢çº§è”å´©æºƒï¼‰
        """
        try:
            from playwright.async_api import async_playwright
        except ImportError:
            logger.warning("ğŸ“¸ playwright æœªå®‰è£…ï¼Œè·³è¿‡æˆªå›¾æ¸²æŸ“")
            return None

        page = None
        try:
            # æ‡’åˆå§‹åŒ–ï¼šé¦–æ¬¡è°ƒç”¨æ—¶å¯åŠ¨æµè§ˆå™¨ï¼ˆåŠ é”é˜²æ­¢å¹¶å‘é‡å¤åˆå§‹åŒ–ï¼‰
            if self._browser is None:
                async with self._browser_lock:
                    if self._browser is None:  # double-check
                        self._playwright = await async_playwright().__aenter__()
                        self._browser = await self._playwright.chromium.launch(
                            headless=True,
                            args=["--disable-gpu", "--disable-dev-shm-usage",
                                  "--no-sandbox", "--disable-extensions"]
                        )
                        logger.info("ğŸ“¸ Playwright æµè§ˆå™¨å·²å¯åŠ¨ï¼ˆæŒä¹…åŒ–å¤ç”¨ï¼‰")

            page = await self._browser.new_page(viewport={"width": 1280, "height": 900})

            # å±è”½æ— å…³èµ„æºï¼šåªä¿ç•™ CSS å’Œå›¾ç‰‡ï¼Œä¿è¯é¡µé¢å¤–è§‚
            async def block_resources(route):
                rt = route.request.resource_type
                url = route.request.url
                if rt in ("stylesheet", "image"):
                    await route.continue_()
                elif rt in ("script", "font", "media", "websocket",
                            "manifest", "other"):
                    await route.abort()
                elif any(x in url for x in ("analytics", "tracking", "beacon",
                                            "ads", "doubleclick", "facebook")):
                    await route.abort()
                else:
                    await route.continue_()

            await page.route("**/*", block_resources)

            # æ³¨å…¥ <base> æ ‡ç­¾ï¼Œä½¿ protocol-relative URL (//...) å’Œç›¸å¯¹è·¯å¾„éƒ½èƒ½æ­£ç¡®è§£æ
            # setContent åœ¨ about:blank ä¸Šä¸‹æ–‡ä¸­è¿è¡Œï¼Œæ²¡æœ‰ base åˆ™ //cdn... ä¼šå˜æˆ about://cdn...
            base_tag = '<base href="https://www.amazon.com/">'
            lower_head = html_content[:2000].lower()
            if "<base " not in lower_head:
                # æ‰¾åˆ° <head> æˆ– <head ...> çš„ç»“æŸä½ç½®
                head_pos = lower_head.find("<head")
                if head_pos != -1:
                    close_pos = html_content.index(">", head_pos) + 1
                    html_content = html_content[:close_pos] + base_tag + html_content[close_pos:]
                else:
                    html_content = base_tag + html_content

            # setContent ç›´æ¥æ³¨å…¥ HTMLï¼ˆæ¯” goto + route æ‹¦æˆªå¿« ~500msï¼‰
            try:
                await page.set_content(
                    html_content,
                    wait_until="domcontentloaded",
                    timeout=15000,
                )
            except Exception:
                pass  # è¶…æ—¶ä¸å½±å“æˆªå›¾

            # ç­‰å¾…ç½‘ç»œç©ºé—²ï¼ˆCSS/å›¾ç‰‡åŠ è½½å®Œæ¯•ï¼‰ï¼Œè¶…æ—¶ 2s å…¼é¡¾é€Ÿåº¦ä¸è´¨é‡
            try:
                await page.wait_for_load_state("networkidle", timeout=2000)
            except Exception:
                pass  # è¶…æ—¶ä»ç»§ç»­æˆªå›¾ï¼Œå¤§éƒ¨åˆ†èµ„æºåº”å·²åŠ è½½

            # è®¡ç®—è£å‰ªé«˜åº¦ï¼šæ‰«æå¤šä¸ªé”šç‚¹å…ƒç´ ï¼Œå–æœ€å¤§ bottom å€¼
            clip_height = await page.evaluate("""() => {
                // é˜²å¾¡ document.body ä¸º nullï¼ˆsetContent å¼‚å¸¸æ—¶å¯èƒ½å‘ç”Ÿï¼‰
                if (!document.body) return 1200;
                const anchors = [
                    '#buybox', '#rightCol', '#buyBoxAccordion',
                    '#add-to-cart-button', '#buy-now-button',
                    '#submitOrderButtonId', '#averageCustomerReviews',
                    '#productOverview_feature_div', '#centerCol',
                    '#apex_desktop_newAccordionRow'
                ];
                let maxBottom = 0;
                for (const sel of anchors) {
                    const el = document.querySelector(sel);
                    if (el) {
                        const rect = el.getBoundingClientRect();
                        if (rect.bottom > maxBottom) maxBottom = rect.bottom;
                    }
                }
                // æ‰¾åˆ°äº†é”šç‚¹å…ƒç´  â†’ åº•éƒ¨åŠ  100px è¾¹è·
                if (maxBottom > 0) return Math.ceil(maxBottom + 100);
                // å…œåº•ï¼šå–é¡µé¢å®é™…é«˜åº¦ï¼Œä½†ä¸è¶…è¿‡ 3000px
                return Math.min(document.body.scrollHeight || 1200, 3000);
            }""")
            clip_height = max(800, min(clip_height, 3000))

            # æˆªå›¾å‰æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å¯è§å†…å®¹ï¼ˆé˜²æ­¢ç©ºç™½æˆªå›¾ï¼‰
            has_content = await page.evaluate("""() => {
                if (!document.body) return false;
                // æ£€æŸ¥æ˜¯å¦æœ‰å¯è§çš„æ–‡æœ¬æˆ–å›¾ç‰‡
                const text = document.body.innerText || '';
                if (text.trim().length > 50) return true;
                const imgs = document.querySelectorAll('img[src]');
                if (imgs.length > 0) return true;
                return false;
            }""")

            screenshot = await page.screenshot(
                type="png",
                clip={"x": 0, "y": 0, "width": 1280, "height": clip_height}
            )

            # ç©ºç™½æ£€æµ‹ï¼šPNG < 10KB ä¸”é¡µé¢æ— å¯è§å†…å®¹ â†’ åˆ¤å®šä¸ºç©ºç™½æˆªå›¾
            if len(screenshot) < 10240 and not has_content:
                logger.warning(f"ğŸ“¸ ç©ºç™½æˆªå›¾å·²ä¸¢å¼ƒ: {asin} ({len(screenshot)} bytes, æ— å¯è§å†…å®¹)")
                return None

            return screenshot
        except Exception as e:
            err_msg = str(e)
            # åªæœ‰æµè§ˆå™¨è¿›ç¨‹çº§å´©æºƒæ‰é‡ç½®æµè§ˆå™¨ï¼›page çº§é”™è¯¯ä¸è¿å
            if "browser has been closed" in err_msg or "Target closed" in err_msg:
                logger.error(f"ğŸ“¸ æµè§ˆå™¨è¿›ç¨‹å´©æºƒï¼Œå°†é‡æ–°å¯åŠ¨: {asin}")
                await self._close_browser()
            else:
                logger.warning(f"ğŸ“¸ é¡µé¢æ¸²æŸ“å¤±è´¥ {asin}: {e}")
            return None
        finally:
            # æ— è®ºæˆåŠŸå¤±è´¥éƒ½å®‰å…¨å…³é—­ pageï¼ˆä¸å½±å“æµè§ˆå™¨å’Œå…¶ä»– pageï¼‰
            if page:
                try:
                    await page.close()
                except Exception:
                    pass

    async def _close_browser(self):
        """å®‰å…¨å…³é—­ Playwright æµè§ˆå™¨ï¼ˆåŠ é”é˜²æ­¢å¹¶å‘å…³é—­å†²çªï¼‰"""
        async with self._browser_lock:
            try:
                if self._browser:
                    await self._browser.close()
            except Exception:
                pass
            try:
                if self._playwright:
                    await self._playwright.__aexit__(None, None, None)
            except Exception:
                pass
            self._browser = None
            self._playwright = None

    async def _upload_screenshot(self, batch_name: str, asin: str, png_bytes: bytes):
        """å°†æˆªå›¾ POST åˆ° Server"""
        try:
            url = f"{self.server_url}/api/tasks/screenshot"
            files = {"file": (f"{asin}.png", png_bytes, "image/png")}
            data = {"batch_name": batch_name, "asin": asin}
            async with httpx.AsyncClient(timeout=15) as client:
                resp = await client.post(url, files=files, data=data)
            if resp.status_code != 200:
                logger.warning(f"æˆªå›¾ä¸Šä¼ å¤±è´¥ {asin}: HTTP {resp.status_code}")
        except Exception as e:
            logger.error(f"æˆªå›¾ä¸Šä¼ å¼‚å¸¸ {asin}: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # éš§é“æ¨¡å¼ IP è½®æ¢ç›‘æ§
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _ip_rotation_watcher(self):
        """
        IP è½®æ¢ç›‘æ§åç¨‹ï¼ˆä»…éš§é“æ¨¡å¼ï¼‰ã€‚

        æ¯ç§’æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ IP è½®æ¢æ—¶é—´ç‚¹ï¼ˆ60s å‘¨æœŸï¼‰ï¼Œ
        è½®æ¢åé‡å»ºæ‰€æœ‰é€šé“çš„ Sessionï¼ˆå…³é—­æ—§è¿æ¥ï¼Œæ–°å»ºèµ°æ–° IP çš„è¿æ¥ï¼‰ã€‚
        """
        logger.info(f"ğŸ”„ IP è½®æ¢ç›‘æ§å¯åŠ¨ (å‘¨æœŸ: {config.TUNNEL_ROTATE_INTERVAL}s)")
        while self._running:
            try:
                await asyncio.sleep(1)
                if not self._running:
                    break

                rotated = await self.proxy_manager.handle_ip_rotation()
                if rotated:
                    logger.info("ğŸ”„ IP è½®æ¢è§¦å‘ï¼Œé‡å»ºæ‰€æœ‰é€šé“ Session...")
                    if self._session_pool:
                        await self._session_pool.rebuild_all()
                    logger.info(f"ğŸ”„ IP è½®æ¢å®Œæˆï¼Œ{self._session_pool.ready_count}/{config.TUNNEL_CHANNELS} é€šé“å°±ç»ª"
                                f" | ä¸‹æ¬¡è½®æ¢: {self.proxy_manager.time_to_next_rotation():.0f}s")

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ğŸ”„ IP è½®æ¢ç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(5)

        logger.info("ğŸ”„ IP è½®æ¢ç›‘æ§é€€å‡º")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ç”Ÿå‘½å‘¨æœŸ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢è‡ªé€‚åº”æ§åˆ¶å™¨
        await self._controller.stop()
        # åˆ·æ–°æ‰¹é‡æäº¤é˜Ÿåˆ—ä¸­çš„å‰©ä½™ç»“æœ
        if self._result_queue:
            await self._flush_results()
        if self._batch_submitter_task:
            self._batch_submitter_task.cancel()
            try:
                await self._batch_submitter_task
            except asyncio.CancelledError:
                pass
        # å…³é—­ Sessionï¼ˆTPS æ¨¡å¼ï¼‰
        if self._session:
            await self._session.close()
        # å…³é—­ SessionPoolï¼ˆéš§é“æ¨¡å¼ï¼‰
        if self._session_pool:
            await self._session_pool.close_all()
        # å…³é—­æŒä¹…åŒ–æµè§ˆå™¨
        await self._close_browser()

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        elapsed = time.time() - self._stats["start_time"] if self._stats["start_time"] else 0
        total = self._stats["total"]
        success = self._stats["success"]
        rate = success / total * 100 if total > 0 else 0
        speed = total / elapsed * 60 if elapsed > 0 else 0

        logger.info("=" * 60)
        logger.info(f"ğŸ“Š Worker [{self.worker_id}] ç»Ÿè®¡")
        logger.info(f"   æ€»é‡‡é›†: {total}")
        logger.info(f"   æˆåŠŸ: {success} ({rate:.1f}%)")
        logger.info(f"   å¤±è´¥: {self._stats['failed']}")
        logger.info(f"   è¢«å°: {self._stats['blocked']}")
        logger.info(f"   é€Ÿåº¦: {speed:.1f} æ¡/åˆ†é’Ÿ")
        logger.info(f"   è€—æ—¶: {elapsed:.0f} ç§’")
        logger.info(f"   æœ€ç»ˆå¹¶å‘: {self._controller.current_concurrency}")
        # æœ€ç»ˆæŒ‡æ ‡å¿«ç…§
        logger.info(self._metrics.format_summary())
        logger.info("=" * 60)


def main():
    """Worker å…¥å£"""
    arg_parser = argparse.ArgumentParser(description="Amazon Scraper Worker (Pipeline + Adaptive)")
    arg_parser.add_argument("--server", required=True, help="ä¸­å¤®æœåŠ¡å™¨åœ°å€ (å¦‚ http://192.168.1.100:8899)")
    arg_parser.add_argument("--worker-id", default=None, help="Worker IDï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰")
    arg_parser.add_argument("--concurrency", type=int, default=None,
                            help=f"æœ€å¤§å¹¶å‘æ•°ä¸Šé™ï¼ˆé»˜è®¤ {config.MAX_CONCURRENCY}ï¼Œè‡ªé€‚åº”æ§åˆ¶å™¨è‡ªåŠ¨æ¢ç´¢æœ€ä¼˜å€¼ï¼‰")
    arg_parser.add_argument("--zip-code", default=None, help=f"é‚®ç¼–ï¼ˆé»˜è®¤ {config.DEFAULT_ZIP_CODE}ï¼‰")
    arg_parser.add_argument("--fast", action="store_true", help="å¿«é€Ÿæ¨¡å¼: AOD ä¼˜å…ˆè·å–ä»·æ ¼æ•°æ®")

    args = arg_parser.parse_args()

    worker = Worker(
        server_url=args.server,
        worker_id=args.worker_id,
        concurrency=args.concurrency,
        zip_code=args.zip_code,
        fast_mode=args.fast,
    )

    # ä¼˜é›…é€€å‡º
    loop = asyncio.new_event_loop()

    def signal_handler(sig, frame):
        logger.info("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        loop.create_task(worker.stop())

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        loop.run_until_complete(worker.start())
    finally:
        loop.close()


if __name__ == "__main__":
    main()
