"""
Amazon äº§å“é‡‡é›†ç³»ç»Ÿ v2 - ä¸­å¤®æœåŠ¡å™¨ï¼ˆFastAPIï¼‰
ç«¯å£ 8899
æä¾› API ç«¯ç‚¹å’Œ Web UI
"""
import os
import io
import csv
import re
import asyncio
import logging
import time
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Optional, List, Dict, Any

from fastapi import FastAPI, Request, UploadFile, File, Form, Query, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import openpyxl

import config
from database import Database, get_db, close_db
from models import RESULT_FIELDS

# æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)

# ==================== ç”Ÿå‘½å‘¨æœŸ ====================

@asynccontextmanager
async def lifespan(app):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # startup
    db = await get_db()
    logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    asyncio.create_task(_timeout_task_loop())
    yield
    # shutdown
    await close_db()
    logger.info("ğŸ›‘ æœåŠ¡å™¨å…³é—­")


# FastAPI åº”ç”¨
app = FastAPI(title="Amazon Scraper v2", version="2.0.0", lifespan=lifespan)

# é™æ€æ–‡ä»¶å’Œæ¨¡æ¿
app.mount("/static", StaticFiles(directory=config.STATIC_DIR), name="static")
templates = Jinja2Templates(directory=config.TEMPLATE_DIR)

# ==================== Worker åœ¨çº¿çŠ¶æ€è¿½è¸ª ====================
# å­˜å‚¨ worker çš„æœ€åå¿ƒè·³æ—¶é—´å’Œç»Ÿè®¡
_worker_registry: Dict[str, Dict] = {}


def _register_worker(worker_id: str):
    """æ³¨å†Œ/æ›´æ–° worker å¿ƒè·³"""
    now = time.time()
    if worker_id not in _worker_registry:
        _worker_registry[worker_id] = {
            "worker_id": worker_id,
            "first_seen": now,
            "last_seen": now,
            "tasks_pulled": 0,
            "results_submitted": 0,
        }
    _worker_registry[worker_id]["last_seen"] = now


# ==================== è¿è¡Œæ—¶è®¾ç½®ï¼ˆå¯é€šè¿‡ API ä¿®æ”¹ï¼‰====================
_runtime_settings = {
    "zip_code": config.DEFAULT_ZIP_CODE,
    "concurrency": config.DEFAULT_CONCURRENCY,
    "proxy_api_url": config.PROXY_API_URL_AUTH,
    "request_interval": config.REQUEST_INTERVAL,
    "max_retries": config.MAX_RETRIES,
}


async def _timeout_task_loop():
    """å®šæœŸå›é€€è¶…æ—¶ processing ä»»åŠ¡"""
    while True:
        try:
            db = await get_db()
            count = await db.reset_timeout_tasks()
            if count > 0:
                logger.info(f"ğŸ”„ å›é€€äº† {count} ä¸ªè¶…æ—¶ä»»åŠ¡")
        except Exception as e:
            logger.error(f"è¶…æ—¶ä»»åŠ¡å›é€€å¼‚å¸¸: {e}")
        await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡


# ==================== API ç«¯ç‚¹ ====================

# --- ä»»åŠ¡ä¸Šä¼  ---
@app.post("/api/upload")
async def upload_asin_file(
    file: UploadFile = File(...),
    batch_name: str = Form(None),
    zip_code: str = Form(None),
):
    """
    ä¸Šä¼  ASIN æ–‡ä»¶ï¼ˆExcel/CSVï¼‰
    è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹ï¼Œæå– ASIN åˆ—
    """
    db = await get_db()
    zip_code = zip_code or _runtime_settings["zip_code"]

    # è‡ªåŠ¨ç”Ÿæˆæ‰¹æ¬¡å
    if not batch_name:
        batch_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    # è¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    filename = file.filename.lower()

    asins = []
    try:
        if filename.endswith(('.xlsx', '.xls')):
            # Excel æ–‡ä»¶
            wb = openpyxl.load_workbook(io.BytesIO(content), read_only=True)
            ws = wb.active
            for row in ws.iter_rows(values_only=True):
                for cell in row:
                    if cell:
                        val = str(cell).strip().upper()
                        # ASIN æ ¼å¼ï¼š10ä½å­—æ¯æ•°å­—ï¼Œä»¥ B å¼€å¤´
                        if re.match(r'^B[0-9A-Z]{9}$', val):
                            asins.append(val)
            wb.close()
        elif filename.endswith('.csv'):
            # CSV æ–‡ä»¶
            text = content.decode('utf-8-sig')
            reader = csv.reader(io.StringIO(text))
            for row in reader:
                for cell in row:
                    val = cell.strip().upper()
                    if re.match(r'^B[0-9A-Z]{9}$', val):
                        asins.append(val)
        else:
            # çº¯æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€ä¸ª ASINï¼‰
            text = content.decode('utf-8-sig')
            for line in text.splitlines():
                val = line.strip().upper()
                if re.match(r'^B[0-9A-Z]{9}$', val):
                    asins.append(val)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")

    if not asins:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ ASIN")

    # å»é‡
    asins = list(dict.fromkeys(asins))

    # åˆ›å»ºä»»åŠ¡
    inserted = await db.create_tasks(batch_name, asins, zip_code)

    return {
        "status": "ok",
        "batch_name": batch_name,
        "total_asins": len(asins),
        "inserted": inserted,
        "zip_code": zip_code,
    }


# --- Worker æ‹‰å–ä»»åŠ¡ ---
@app.get("/api/tasks/pull")
async def pull_tasks(
    worker_id: str = Query(...),
    count: int = Query(10),
):
    """Worker æ‹‰å–å¾…å¤„ç†ä»»åŠ¡"""
    db = await get_db()
    _register_worker(worker_id)
    
    tasks = await db.pull_tasks(worker_id, min(count, 50))
    
    if worker_id in _worker_registry:
        _worker_registry[worker_id]["tasks_pulled"] += len(tasks)

    return {"tasks": tasks}


# --- Worker æäº¤ç»“æœ ---
@app.post("/api/tasks/result")
async def submit_result(request: Request):
    """Worker æäº¤é‡‡é›†ç»“æœ"""
    db = await get_db()
    data = await request.json()
    
    task_id = data.get("task_id")
    worker_id = data.get("worker_id", "unknown")
    success = data.get("success", False)
    result_data = data.get("result")

    _register_worker(worker_id)
    if worker_id in _worker_registry:
        _worker_registry[worker_id]["results_submitted"] += 1

    if success and result_data:
        # ä¿å­˜ç»“æœ
        await db.save_result(result_data)
        await db.mark_task_done(task_id, worker_id)
    else:
        await db.mark_task_failed(task_id, worker_id)

    return {"status": "ok"}


# --- Worker æ‰¹é‡æäº¤ç»“æœ ---
@app.post("/api/tasks/result/batch")
async def submit_result_batch(request: Request):
    """Worker æ‰¹é‡æäº¤é‡‡é›†ç»“æœï¼ˆç»Ÿä¸€æäº¤ï¼Œå‡å°‘ç£ç›˜ IOï¼‰"""
    db = await get_db()
    data = await request.json()
    results_list = data.get("results", [])

    try:
        for item in results_list:
            task_id = item.get("task_id")
            worker_id = item.get("worker_id", "unknown")
            success = item.get("success", False)
            result_data = item.get("result")

            _register_worker(worker_id)
            if worker_id in _worker_registry:
                _worker_registry[worker_id]["results_submitted"] += 1

            now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
            if success and result_data:
                # ä¿å­˜ç»“æœï¼ˆä¸å•ç‹¬ commitï¼‰
                fields = ["batch_name", "asin"] + [f for f in RESULT_FIELDS if f != "asin"]
                values = [result_data.get(f, "") for f in fields]
                placeholders = ",".join(["?"] * len(fields))
                field_names = ",".join(fields)
                await db._db.execute(
                    f"INSERT OR REPLACE INTO results ({field_names}) VALUES ({placeholders})",
                    values
                )
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                await db._db.execute(
                    "UPDATE tasks SET status = 'done', worker_id = ?, updated_at = ? WHERE id = ?",
                    (worker_id, now, task_id)
                )
            else:
                # æ ‡è®°ä»»åŠ¡å¤±è´¥
                await db._db.execute(
                    """UPDATE tasks
                       SET status = 'failed', worker_id = ?, retry_count = retry_count + 1, updated_at = ?
                       WHERE id = ?""",
                    (worker_id, now, task_id)
                )

        # æ•´æ‰¹ç»Ÿä¸€ commit
        await db._db.commit()
    except Exception:
        await db._db.rollback()
        raise

    return {"status": "ok", "count": len(results_list)}


# --- è¿›åº¦æŸ¥è¯¢ ---
@app.get("/api/progress/{batch_name}")
async def get_progress(batch_name: str):
    """è·å–æŒ‡å®šæ‰¹æ¬¡çš„é‡‡é›†è¿›åº¦"""
    db = await get_db()
    progress = await db.get_progress(batch_name)
    return progress


@app.get("/api/progress")
async def get_overall_progress():
    """è·å–æ€»ä½“è¿›åº¦"""
    db = await get_db()
    progress = await db.get_progress()
    return progress


# --- æ‰¹æ¬¡åˆ—è¡¨ ---
@app.get("/api/batches")
async def get_batches():
    """è·å–æ‰€æœ‰æ‰¹æ¬¡åˆ—è¡¨"""
    db = await get_db()
    batches = await db.get_batch_list()
    return {"batches": batches}


# --- ç»“æœæŸ¥è¯¢ ---
@app.get("/api/results")
async def get_results(
    batch_name: str = Query(None),
    page: int = Query(1),
    per_page: int = Query(50),
    search: str = Query(None),
):
    """åˆ†é¡µè·å–é‡‡é›†ç»“æœ"""
    db = await get_db()
    results, total = await db.get_results(batch_name, page, per_page, search)
    return {
        "results": results,
        "total": total,
        "page": page,
        "per_page": per_page,
        "total_pages": (total + per_page - 1) // per_page,
    }


# --- æ•°æ®å¯¼å‡º ---
@app.get("/api/export/{batch_name}")
async def export_data(
    batch_name: str,
    format: str = Query("excel"),
):
    """å¯¼å‡ºé‡‡é›†æ•°æ®ï¼ˆExcel/CSVï¼‰"""
    db = await get_db()
    results = await db.get_all_results(batch_name)

    if not results:
        raise HTTPException(status_code=404, detail="è¯¥æ‰¹æ¬¡æ— æ•°æ®")

    if format == "csv":
        return _export_csv(results, batch_name)
    else:
        return _export_excel(results, batch_name)


def _export_excel(results: List[Dict], batch_name: str):
    """å¯¼å‡º Excel æ–‡ä»¶"""
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "é‡‡é›†ç»“æœ"

    # å†™è¡¨å¤´ï¼ˆä½¿ç”¨ä¸­æ–‡ï¼‰
    headers = []
    field_keys = []
    for field in RESULT_FIELDS:
        cn_name = config.HEADER_MAP.get(field, field)
        headers.append(cn_name)
        field_keys.append(field)

    ws.append(headers)

    # å†™æ•°æ®
    for row_data in results:
        row = [str(row_data.get(f, "")) for f in field_keys]
        ws.append(row)

    # ä¿å­˜åˆ°å†…å­˜
    output = io.BytesIO()
    wb.save(output)
    output.seek(0)

    filename = f"{batch_name}.xlsx"
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": f"attachment; filename={filename}"},
    )


def _export_csv(results: List[Dict], batch_name: str):
    """å¯¼å‡º CSV æ–‡ä»¶"""
    output = io.StringIO()
    writer = csv.writer(output)

    # è¡¨å¤´
    headers = [config.HEADER_MAP.get(f, f) for f in RESULT_FIELDS]
    writer.writerow(headers)

    # æ•°æ®
    for row_data in results:
        row = [str(row_data.get(f, "")) for f in RESULT_FIELDS]
        writer.writerow(row)

    content = output.getvalue().encode('utf-8-sig')
    filename = f"{batch_name}.csv"
    return StreamingResponse(
        io.BytesIO(content),
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={filename}"},
    )


# --- Worker ç›‘æ§ ---
@app.get("/api/workers")
async def get_workers():
    """è·å–åœ¨çº¿ worker åˆ—è¡¨"""
    now = time.time()
    workers = []
    for wid, info in _worker_registry.items():
        elapsed = now - info["last_seen"]
        workers.append({
            "worker_id": wid,
            "status": "online" if elapsed < 60 else "offline",
            "last_seen": datetime.fromtimestamp(info["last_seen"]).strftime("%H:%M:%S"),
            "tasks_pulled": info["tasks_pulled"],
            "results_submitted": info["results_submitted"],
            "uptime": int(now - info["first_seen"]),
        })
    return {"workers": workers}


# --- è®¾ç½®ç®¡ç† ---
@app.get("/api/settings")
async def get_settings():
    """è·å–å½“å‰è¿è¡Œæ—¶è®¾ç½®"""
    return _runtime_settings.copy()


@app.put("/api/settings")
async def update_settings(request: Request):
    """æ›´æ–°è¿è¡Œæ—¶è®¾ç½®"""
    data = await request.json()
    for key in _runtime_settings:
        if key in data:
            _runtime_settings[key] = data[key]
    return {"status": "ok", "settings": _runtime_settings}


# --- æ‰¹æ¬¡æ“ä½œ ---
@app.post("/api/batches/{batch_name}/retry")
async def retry_batch(batch_name: str):
    """é‡è¯•æ‰¹æ¬¡ä¸­æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡"""
    db = await get_db()
    await db.retry_all_failed(batch_name)
    return {"status": "ok"}


@app.delete("/api/batches/{batch_name}")
async def delete_batch(batch_name: str):
    """åˆ é™¤æ‰¹æ¬¡"""
    db = await get_db()
    await db.delete_batch(batch_name)
    return {"status": "ok"}


# ==================== Web UI è·¯ç”± ====================

@app.get("/", response_class=HTMLResponse)
async def dashboard(request: Request):
    """ä»ªè¡¨ç›˜é¦–é¡µ"""
    db = await get_db()
    progress = await db.get_progress()
    batches = await db.get_batch_list()
    
    # è®¡ç®—é€Ÿåº¦ï¼ˆæœ€è¿‘5åˆ†é’Ÿçš„å®Œæˆæ•°ï¼‰
    now = time.time()
    active_workers = sum(1 for w in _worker_registry.values() if now - w["last_seen"] < 60)

    return templates.TemplateResponse("dashboard.html", {
        "request": request,
        "progress": progress,
        "batches": batches[:5],  # æœ€è¿‘5ä¸ªæ‰¹æ¬¡
        "active_workers": active_workers,
        "total_workers": len(_worker_registry),
    })


@app.get("/tasks", response_class=HTMLResponse)
async def tasks_page(request: Request):
    """ä»»åŠ¡ç®¡ç†é¡µé¢"""
    db = await get_db()
    batches = await db.get_batch_list()
    return templates.TemplateResponse("tasks.html", {
        "request": request,
        "batches": batches,
    })


@app.get("/results", response_class=HTMLResponse)
async def results_page(
    request: Request,
    batch_name: str = None,
    page: int = 1,
    search: str = None,
):
    """ç»“æœæµè§ˆé¡µé¢"""
    db = await get_db()
    batches = await db.get_batch_list()
    results, total = await db.get_results(batch_name, page, 50, search)
    total_pages = (total + 49) // 50
    progress = await db.get_progress(batch_name)

    return templates.TemplateResponse("results.html", {
        "request": request,
        "results": results,
        "batches": batches,
        "current_batch": batch_name,
        "current_page": page,
        "total": total,
        "total_pages": total_pages,
        "search": search or "",
        "progress": progress,
    })


@app.get("/settings", response_class=HTMLResponse)
async def settings_page(request: Request):
    """è®¾ç½®é¡µé¢"""
    return templates.TemplateResponse("settings.html", {
        "request": request,
        "settings": _runtime_settings,
        "config": {
            "port": config.SERVER_PORT,
            "impersonate": config.IMPERSONATE_BROWSER,
            "timeout": config.REQUEST_TIMEOUT,
            "rotate_every": config.SESSION_ROTATE_EVERY,
        },
    })


@app.get("/workers", response_class=HTMLResponse)
async def workers_page(request: Request):
    """Worker ç›‘æ§é¡µé¢"""
    now = time.time()
    workers = []
    for wid, info in _worker_registry.items():
        elapsed = now - info["last_seen"]
        workers.append({
            "worker_id": wid,
            "status": "online" if elapsed < 60 else "offline",
            "last_seen": datetime.fromtimestamp(info["last_seen"]).strftime("%Y-%m-%d %H:%M:%S"),
            "tasks_pulled": info["tasks_pulled"],
            "results_submitted": info["results_submitted"],
            "uptime_min": int((now - info["first_seen"]) / 60),
        })
    return templates.TemplateResponse("workers.html", {
        "request": request,
        "workers": workers,
    })


# ==================== ä¸»å…¥å£ ====================

if __name__ == "__main__":
    uvicorn.run(
        "server:app",
        host=config.SERVER_HOST,
        port=config.SERVER_PORT,
        reload=False,
        log_level="info",
    )
